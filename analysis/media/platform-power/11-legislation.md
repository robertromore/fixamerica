# Platform Power: Legislation and Legal Framework

## Overview

Regulating platform power requires action across multiple dimensions: reforming Section 230 liability protections, mandating transparency, enforcing antitrust law, requiring platform payments to news publishers, and establishing comprehensive digital markets regulation. This document provides draft legal text for key reforms.

## Federal Legislation

### Platform Transparency and Accountability Act

**Purpose**: Require large platforms to disclose information about algorithms, content moderation, and advertising.

**Draft Text**:

```text
SECTION 1. SHORT TITLE.

This Act may be cited as the "Platform Transparency and Accountability
Act of 2025".

SEC. 2. DEFINITIONS.

(a) COVERED PLATFORM.—A "covered platform" means an online platform
that—
    (1) has more than 50 million monthly active users in the United
    States; or
    (2) has more than $1 billion in annual revenue.

(b) ALGORITHMIC SYSTEM.—An "algorithmic system" means any automated
system that selects, ranks, recommends, or amplifies content for users.

SEC. 3. TRANSPARENCY REQUIREMENTS.

(a) ALGORITHM DISCLOSURE.—Each covered platform shall publish, at
least annually, a description of—
    (1) the primary factors used in algorithmic systems to rank or
    recommend content;
    (2) how engagement metrics influence content visibility;
    (3) major changes to algorithmic systems; and
    (4) the platform's processes for evaluating algorithmic impact.

(b) CONTENT MODERATION TRANSPARENCY.—Each covered platform shall
publish quarterly reports including—
    (1) the number of content removal actions by category;
    (2) the number of account suspensions and terminations;
    (3) the number of appeals and reversal rates;
    (4) enforcement actions by country and language;
    (5) use of automated versus human review; and
    (6) error rates in automated enforcement.

(c) ADVERTISING TRANSPARENCY.—Each covered platform shall maintain
a publicly accessible, searchable archive of—
    (1) all political advertisements;
    (2) issue advertisements related to matters of public importance;
    (3) information about targeting criteria used; and
    (4) amount paid and impressions served.

SEC. 4. RESEARCH ACCESS.

(a) REQUIREMENT.—Each covered platform shall provide qualified
researchers access to data necessary to study—
    (1) the spread of misinformation;
    (2) algorithmic amplification effects;
    (3) platform impact on democratic discourse; and
    (4) other matters of significant public interest.

(b) PRIVACY PROTECTIONS.—Access under this section shall be
subject to privacy protections determined by the Commission.

(c) QUALIFIED RESEARCHER.—The Commission shall establish criteria
for qualifying as a researcher under this section.

SEC. 5. USER CONTROLS.

Each covered platform shall provide users with—
    (1) the option to view content chronologically without algorithmic
    curation;
    (2) controls to adjust or disable personalized recommendations;
    (3) information about why specific content was recommended; and
    (4) the ability to download their data in a portable format.

SEC. 6. ENFORCEMENT.

(a) FTC ENFORCEMENT.—The Federal Trade Commission shall enforce
this Act.

(b) PENALTIES.—Violations shall be subject to civil penalties of
up to $50,000 per day per violation.

(c) RULEMAKING.—The Commission shall promulgate rules implementing
this Act within 18 months of enactment.

SEC. 7. EFFECTIVE DATE.

This Act shall take effect 180 days after enactment.
```

### Section 230 Reform Act

**Purpose**: Modify Section 230 immunity to address algorithmic amplification and require transparency.

**Draft Text**:

```text
SECTION 1. SHORT TITLE.

This Act may be cited as the "Section 230 Reform Act of 2025".

SEC. 2. AMENDMENT TO SECTION 230.

Section 230 of the Communications Act of 1934 (47 U.S.C. 230) is
amended—

(a) By amending subsection (c) to read as follows:

"(c) PROTECTION FOR 'GOOD SAMARITAN' BLOCKING AND SCREENING.—

"(1) TREATMENT OF PUBLISHER OR SPEAKER.—No provider or user of an
interactive computer service shall be treated as the publisher or
speaker of any information provided by another information content
provider, except—

    "(A) to the extent that the provider uses an algorithmic system
    to amplify, recommend, or target such information to users based
    on engagement optimization or personalization, in which case the
    provider may be held liable for such amplification if it
    materially contributes to harm caused by such information; or

    "(B) with respect to paid content, where the provider shall be
    treated as the publisher to the same extent as a publisher of
    advertising."

(b) By adding at the end the following new subsection:

"(f) TRANSPARENCY CONDITION.—

"(1) The protections under subsection (c)(1) shall not apply to any
interactive computer service that fails to comply with transparency
requirements established by the Federal Trade Commission regarding—

    "(A) content moderation policies and enforcement;
    "(B) algorithmic recommendation systems; and
    "(C) advertising practices.

"(2) The Commission shall promulgate rules establishing such
transparency requirements within 18 months of the enactment of this
subsection."

(c) By adding the following subsection:

"(g) PRESERVATION OF STATE LAW.—Nothing in this section shall be
construed to preempt any State law that—

    "(1) requires transparency regarding content moderation or
    algorithmic systems;
    "(2) provides consumer protection regarding platform practices; or
    "(3) addresses privacy or data protection."
```

**Explanation**:

- Preserves core Section 230 protection for hosting user content
- Creates exception for algorithmic amplification that causes harm
- Removes protection for paid/promoted content
- Conditions protection on transparency compliance
- Preserves state law authority

### Digital Platform Competition Act

**Purpose**: Establish antitrust rules specific to dominant digital platforms.

**Draft Text**:

```text
SECTION 1. SHORT TITLE.

This Act may be cited as the "Digital Platform Competition Act of 2025".

SEC. 2. COVERED PLATFORM DESIGNATION.

(a) CRITERIA.—The Federal Trade Commission shall designate as a
"covered platform" any online platform that—
    (1) has more than 50 million U.S. monthly active users and more
    than $100 billion in market capitalization; or
    (2) controls a critical distribution channel for online services.

(b) REVIEW.—Designations shall be reviewed every 3 years.

SEC. 3. PROHIBITED CONDUCT.

A covered platform may not—
    (1) give preference to its own products or services over those
    of competitors in search results, rankings, or other displays;
    (2) use non-public data obtained from business users to compete
    against those users;
    (3) condition access to platform services on purchase of other
    services;
    (4) require most-favored-nation pricing terms;
    (5) prevent business users from communicating with their
    customers; or
    (6) prevent users from uninstalling pre-installed applications.

SEC. 4. INTEROPERABILITY.

(a) REQUIREMENT.—Covered platforms shall enable interoperability
with competing services where technically feasible.

(b) MESSAGING.—Covered platforms operating messaging services with
more than 50 million users shall enable interoperability with other
messaging services within 2 years.

SEC. 5. MERGER REVIEW.

(a) PRESUMPTION.—Any acquisition by a covered platform of a company
with revenue exceeding $100 million shall be presumptively unlawful.

(b) REBUTTAL.—The presumption may be rebutted only by clear and
convincing evidence that the acquisition will not harm competition.

SEC. 6. ENFORCEMENT.

(a) FTC AUTHORITY.—The Federal Trade Commission shall enforce this
Act.

(b) PENALTIES.—Violations shall be subject to civil penalties of up
to 15 percent of U.S. revenue for the preceding year.

(c) PRIVATE RIGHT OF ACTION.—Any person injured by a violation of
this Act may bring a civil action for damages and injunctive relief.

SEC. 7. EFFECTIVE DATE.

This Act shall take effect upon enactment.
```

### Journalism Competition and Preservation Act

**Purpose**: Enable news publishers to negotiate collectively with platforms.

**Draft Text**:

```text
SECTION 1. SHORT TITLE.

This Act may be cited as the "Journalism Competition and Preservation
Act of 2025".

SEC. 2. SAFE HARBOR.

(a) IN GENERAL.—A news content creator may, for a period of 8 years
beginning on the date of enactment, jointly negotiate with a covered
platform regarding the terms on which the content of the news content
creator may be distributed by such platform.

(b) LIMITATION.—This section does not authorize agreements regarding
subscription pricing or agreements with non-news entities.

SEC. 3. MANDATORY NEGOTIATION.

(a) DUTY.—A covered platform shall negotiate in good faith with any
group of news content creators representing at least 20 percent of
total online news traffic.

(b) BINDING ARBITRATION.—If the parties fail to reach agreement
within 180 days, either party may invoke binding final-offer
arbitration.

(c) ARBITRATION FACTORS.—The arbitrator shall consider—
    (1) the value of news content to the platform;
    (2) the benefit to news creators from platform distribution;
    (3) the quality and cost of content creation; and
    (4) the public interest in sustaining journalism.

SEC. 4. NON-DISCRIMINATION.

(a) PROHIBITION.—A covered platform may not discriminate against a
news content creator based on participation in negotiations under
this Act.

(b) NEWS REMOVAL.—If a covered platform removes news content from
users in any State in response to this Act, the platform shall be
subject to additional obligations as determined by the Commission.

SEC. 5. DEFINITIONS.

(a) COVERED PLATFORM.—A platform with more than 50 million monthly
active U.S. users that distributes news content.

(b) NEWS CONTENT CREATOR.—An entity that employs journalists and
produces original news content.
```

## State Model Legislation

### Model State Platform Accountability Act

```text
SECTION 1. SHORT TITLE.

This Act may be cited as the "[State] Platform Accountability Act".

SECTION 2. CONSUMER PROTECTION.

(a) A social media platform operating in this State shall—
    (1) provide users access to their data in portable format;
    (2) allow users to opt out of algorithmic content curation;
    (3) disclose when content is promoted or paid; and
    (4) provide notice before significant changes to terms of service.

(b) Violations constitute unfair trade practices under [State
consumer protection law].

SECTION 3. YOUTH PROTECTION.

Social media platforms shall not—
    (1) use algorithmic systems optimized for engagement to serve
    content to users under 18; or
    (2) collect location data from users under 18 without parental
    consent.

SECTION 4. ENFORCEMENT.

The Attorney General may enforce this Act.

SECTION 5. EFFECTIVE DATE.

This Act takes effect January 1, [year].
```

## Constitutional Considerations

### First Amendment Analysis

| Issue | Analysis |
|-------|----------|
| **Editorial discretion** | Platforms have some editorial rights |
| **Compelled speech** | Transparency is not content mandate |
| **Content neutrality** | Regulations should be content-neutral |
| **Government interest** | Competition, transparency are compelling |

**Key Principle**: Structural regulation (transparency, competition, payment) is more likely to survive than content-based mandates.

### Commerce Clause

Congress has clear authority to regulate interstate digital commerce.

### Preemption

Federal law should be a floor, not a ceiling—preserve state authority to go further.

## Loopholes, Shortcomings, and Rectification

### Potential Loopholes

| Loophole | Description | Severity |
|----------|-------------|----------|
| **Definition gaming** | Restructure to avoid thresholds | High |
| **Compliance theater** | Minimal disclosure, maximum opacity | High |
| **Jurisdiction shopping** | Operate from outside U.S. | Medium |
| **Algorithm obfuscation** | Disclose without explaining | Medium |

### Shortcomings

| Issue | Impact | Root Cause |
|-------|--------|------------|
| **Enforcement capacity** | Agencies overwhelmed | Resource constraints |
| **Technology evolution** | Laws become outdated | Static rules |
| **International operations** | Cross-border enforcement | Sovereignty limits |

### Rectification Procedures

1. **Broad functional definitions** rather than numeric thresholds
2. **Meaningful disclosure standards** with specificity requirements
3. **Regular review and update** mechanisms built in
4. **Private rights of action** to supplement agency enforcement
5. **International coordination** provisions
6. **Adaptive regulation** authority for agencies

## References

### Key Cases

- *Reno v. ACLU*, 521 U.S. 844 (1997)
- *Gonzalez v. Google*, 598 U.S. ___ (2023)
- *Twitter v. Taamneh*, 598 U.S. ___ (2023)
- *NetChoice v. Paxton* (pending)

### Statutory References

- 47 U.S.C. § 230 (Section 230)
- 15 U.S.C. § 1-7 (Sherman Act)
- 15 U.S.C. § 45 (FTC Act Section 5)

### International References

- EU Digital Services Act, Regulation 2022/2065
- EU Digital Markets Act, Regulation 2022/1925
- Australia News Media and Digital Platforms Mandatory Bargaining Code

---

## Document Navigation

- Previous: [Actions](10-actions.md)
- Up: [Overview](01-overview.md)
