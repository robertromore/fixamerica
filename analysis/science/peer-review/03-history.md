# Peer Review: History

## Origins and Early Development

### Before Formal Peer Review (Pre-1665)

Scientific knowledge before the modern era was disseminated through personal correspondence, books, and patronage networks. Quality control, such as it was, relied on the reputation of the author and the judgment of individual readers. The concept of systematic evaluation by peers did not exist.

- **Ancient and medieval scholarship**: Knowledge validated through authority (Aristotle, Galen) rather than empirical review
- **Renaissance natural philosophy**: Correspondence networks (e.g., Mersenne's circle) served as informal peer evaluation
- **Royal patronage**: Monarchs and nobles funded research based on personal interest, not expert evaluation

### The Birth of Scientific Journals (1665)

The modern peer review system traces its origins to 1665, when two publications launched simultaneously:

| Journal | Founded | Location | Significance |
|---------|---------|----------|-------------|
| *Journal des Savants* | January 5, 1665 | Paris | First scientific journal; book reviews and summaries |
| *Philosophical Transactions of the Royal Society* | March 6, 1665 | London | First journal publishing original research |

Henry Oldenburg, the first editor of *Philosophical Transactions*, established the practice of sending manuscripts to knowledgeable members of the Royal Society for comment before publication. This was not formalized peer review in the modern sense but rather editorial consultation.

### Early Editorial Review (1665-1900)

For most of this period, "peer review" meant editorial judgment rather than external evaluation:

- **Editors as gatekeepers**: Journal editors, often distinguished scientists themselves, made acceptance decisions personally
- **Royal Society Committee on Papers (1752)**: Established a formal committee to evaluate submissions, one of the earliest institutional review mechanisms
- **Limited scope**: Most journals published nearly everything submitted; the volume was manageable
- **No anonymity**: Authors and evaluators typically knew each other in small scientific communities

## The Formalization of Peer Review (1900-1960)

### Professionalization of Science

The late 19th and early 20th centuries saw science transform from a gentleman's pursuit to a professional enterprise:

- **Growth of universities**: More scientists producing more research
- **Disciplinary specialization**: Editors could no longer evaluate all submissions personally
- **Government funding begins**: World War I and II demonstrated science's strategic value
- **Publication volume increases**: Need for systematic filtering emerged

### Key Developments

| Period | Development | Impact |
|--------|-------------|--------|
| 1900-1920 | Specialty journals proliferate | Editors need external expertise |
| 1930s | Referee systems become common at major journals | External review normalized |
| 1940s | Government research funding expands (OSRD, Manhattan Project) | Need for grant review emerges |
| 1945 | Vannevar Bush's *Science, The Endless Frontier* | Argues for merit-based research funding |
| 1950 | NSF established | Peer review mandated for grant allocation |

### The NSF Model (1950)

The National Science Foundation's creation in 1950 established a precedent: federal research funding would be allocated through merit-based peer review rather than political patronage or agency discretion. Key features:

- Expert panels evaluate proposals
- Scientific merit as primary criterion
- Program officers facilitate but do not dictate outcomes
- Established the template for other agencies

### NIH Study Sections (1946)

The National Institutes of Health formalized its study section system in 1946 through the Division of Research Grants (now the Center for Scientific Review):

- Standing committees of experts in defined scientific areas
- Chartered with specific scientific scope
- Members serve rotating terms
- Dual review system: study section scores, then advisory council approves

## The Modern System Takes Shape (1960-1990)

### The Anonymous Review Revolution

The shift to anonymous (blind) review was gradual and uneven:

| Decade | Development |
|--------|-------------|
| 1950s | Some journals begin anonymizing reviewer identity |
| 1960s | Single-blind review becomes standard practice |
| 1970s | Double-blind review advocated; adopted by some social science journals |
| 1980s | Debate intensifies over blind vs. open review |

### The Peer Review Debates of the 1970s-1980s

Several landmark events brought critical scrutiny to peer review:

**Peters and Ceci Experiment (1982)**

- Resubmitted 12 already-published articles to the same journals, changing author names and institutions
- 3 detected as resubmissions; 8 of the remaining 9 were rejected
- Demonstrated that institutional prestige, not content quality, drove decisions
- Published in *Behavioral and Brain Sciences*, sparking intense debate

**First International Congress on Peer Review (1989)**

- Organized by *JAMA* editor Drummond Rennie
- Established peer review as a subject worthy of empirical study
- Led to ongoing International Congress on Peer Review and Biomedical Publication
- Revealed how little evidence supported the effectiveness of peer review

### Expansion of Federal Review

| Year | Development |
|------|-------------|
| 1962 | NIH mandates study section review for all research grants |
| 1975 | NSF formalizes panel review process |
| 1978 | DOE establishes merit review for basic research |
| 1985 | OMB Circular A-110 requires peer review for federally funded research |

### The Rise of Impact Factor (1975)

Eugene Garfield's Institute for Scientific Information (ISI) began publishing Journal Citation Reports in 1975, introducing the Journal Impact Factor (JIF). Though intended as a library tool for journal selection, JIF rapidly became:

- A proxy for individual researcher quality
- A criterion for hiring, promotion, and tenure
- A target for journal editors seeking to boost prestige
- A distorting force in scientific publication

## Crises and Challenges (1990-2010)

### The Reproducibility Problem Emerges

- Pharmaceutical companies report inability to replicate academic findings (~65-90% failure rates)
- John Ioannidis publishes "Why Most Published Research Findings Are False" (2005)
- Peer review implicated as failing to catch methodological weaknesses
- Questions raised about whether reviewers check data and methods adequately

### Publication Bias Documented

- Systematic evidence that positive results published at 3-4x rate of null results
- "File drawer problem" recognized: thousands of studies never submitted
- Registered clinical trials requirement (2005) begins to address bias in medicine
- Peer review system recognized as contributing to, not preventing, publication bias

### The Predatory Publishing Explosion

| Period | Development |
|--------|-------------|
| 2005-2010 | Open access movement creates new journal models |
| 2008 | Jeffrey Beall begins tracking predatory publishers |
| 2010-2015 | Predatory journals proliferate, exploiting author-pays model |
| 2013 | John Bohannon's "sting" operation: 157 of 304 open-access journals accept fake paper |
| 2017 | Beall's list removed under legal pressure; problem continues |

### The Sokal Affair and Its Legacy (1996)

Physicist Alan Sokal submitted a deliberately nonsensical paper to *Social Text*, which published it without peer review (the journal did not use formal review). The incident:

- Highlighted inconsistencies in review practices across disciplines
- Sparked debate about standards in humanities vs. sciences
- Led to broader scrutiny of how peer review functions (or fails) across fields

## The Digital Transformation (2000-Present)

### Online Submission Systems

| System | Launched | Impact |
|--------|----------|--------|
| ScholarOne | 2001 | Standardized manuscript handling |
| Editorial Manager | 2001 | Automated reviewer matching |
| eJournalPress | 2002 | NIH manuscript submission |
| Open Journal Systems (OJS) | 2001 | Free tool for small journals |

These systems accelerated submission rates while enabling tracking of review metrics, inadvertently documenting the system's growing strain.

### The Preprint Revolution

| Year | Development |
|------|-------------|
| 1991 | Paul Ginsparg launches arXiv at Los Alamos |
| 2003 | arXiv moves to Cornell; becomes physics standard |
| 2013 | bioRxiv launches for biology |
| 2019 | medRxiv launches for medical research |
| 2020-2021 | COVID-19 pandemic accelerates preprint adoption across all fields |
| 2023 | eLife adopts reviewed-preprint-only model |

### Open Peer Review Experiments

| Year | Initiative | Model |
|------|-----------|-------|
| 1999 | *BMJ* begins signing reviewer reports | Open identity |
| 2006 | *Nature* trials open review (discontinued) | Optional public comment |
| 2007 | *PLoS ONE* launches with "soundness not significance" review | Reduced gatekeeping |
| 2012 | *PeerJ* launches with open review option | Author choice |
| 2013 | *F1000Research* launches post-publication review | Full transparency |
| 2016 | *Peer Community In* launches | Community-driven overlay review |
| 2023 | *eLife* adopts reviewed preprint model | No accept/reject decisions |

### DORA and the Impact Factor Rebellion (2012-Present)

The San Francisco Declaration on Research Assessment (DORA), launched in 2012, called on institutions and funders to stop using journal impact factors as proxies for research quality. By 2025:

- Over 3,000 organizations and 20,000 individuals have signed
- Several countries (Netherlands, UK) have incorporated DORA principles into national assessment frameworks
- Impact factor remains deeply embedded in hiring and promotion despite growing opposition

## Key Historical Lessons

### What History Reveals

1. **Peer review was never designed for its current role**: It evolved from informal editorial consultation to a system expected to validate all scientific knowledge
2. **Anonymity was an add-on**: Blind review became standard only in the mid-20th century and remains imperfect
3. **Grant review is relatively recent**: Merit-based funding allocation is a post-WWII invention, not an ancient tradition
4. **Impact factor hijacked the purpose**: A library metric became a career-defining number, distorting the entire system
5. **Preprints predate journals**: Scientists shared findings before journals existed; preprints are a return to earlier norms
6. **Every era's reforms created new problems**: Anonymous review reduced some biases but enabled others; online systems increased efficiency but also volume

### Unresolved Historical Tensions

| Tension | First Emerged | Still Unresolved? |
|---------|--------------|-------------------|
| Expert judgment vs. objectivity | 1665 | Yes |
| Anonymity vs. accountability | 1950s | Yes |
| Speed vs. thoroughness | 1970s | Yes |
| Gatekeeping vs. inclusivity | 1980s | Yes |
| Prestige metrics vs. research quality | 1975 | Yes |
| Volume growth vs. reviewer capacity | 1990s | Yes |

## Sources

- Burnham, John C. "The Evolution of Editorial Peer Review." *JAMA* 263, no. 10 (1990): 1323-1329.
- Csiszar, Alex. *The Scientific Journal: Authorship and the Politics of Knowledge in the Nineteenth Century.* Chicago: University of Chicago Press, 2018.
- Peters, Douglas P., and Stephen J. Ceci. "Peer-Review Practices of Psychological Journals." *Behavioral and Brain Sciences* 5, no. 2 (1982): 187-195.
- Rennie, Drummond. "Editorial Peer Review: Its Development and Rationale." In *Peer Review in Health Sciences*, edited by Fiona Godlee and Tom Jefferson, 1-13. London: BMJ Books, 2003.
- Sokal, Alan. "Transgressing the Boundaries: Toward a Transformative Hermeneutics of Quantum Gravity." *Social Text* 46/47 (1996): 217-252.
- Garfield, Eugene. "Citation Analysis as a Tool in Journal Evaluation." *Science* 178, no. 4060 (1972): 471-479.
- Baldwin, Melinda. *Making "Nature": The History of a Scientific Journal.* Chicago: University of Chicago Press, 2015.
- Bush, Vannevar. *Science, The Endless Frontier.* Washington, DC: United States Government Printing Office, 1945.

## Document Navigation

- Previous: [Current State](02-current-state.md)
- Next: [Root Causes](04-root-causes.md)
- Up: [Science](../01-overview.md)
