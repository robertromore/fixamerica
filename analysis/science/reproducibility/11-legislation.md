# Reproducibility: Legislation and Legal Framework

## Overview

Legislation addressing research reproducibility must navigate the tension between ensuring the reliability of publicly funded research and preserving the scientific freedom necessary for creative inquiry. The legislative approach presented here focuses on two complementary strategies: (1) mandating transparency, pre-registration, and data sharing for federally funded research through conditions on grants and contracts, and (2) establishing dedicated funding and institutional infrastructure for systematic replication of influential findings. These approaches work within existing constitutional authority over federal spending and avoid direct regulation of private research.

## Constitutional Amendments

No constitutional amendments are needed for reproducibility reform. The proposed legislation operates through Congress's well-established spending power (Art. I, Section 8, Clause 1) and its authority to organize executive agencies. Conditions on federal grants are constitutional so long as they are related to the purpose of the federal spending program, which reproducibility conditions clearly are.

## Federal Legislation

### Bill 1: Research Reproducibility and Integrity Act

**Purpose**: Establish comprehensive reproducibility requirements for all federally funded research, including mandatory pre-registration of confirmatory studies, data and code sharing, enhanced methods reporting, and institutional accountability for research rigor.

**Draft Text**:

```text
SEC. 1. SHORT TITLE.

This Act may be cited as the "Research Reproducibility and
Integrity Act".

SEC. 2. FINDINGS AND PURPOSE.

(a) FINDINGS.--Congress finds the following:
    (1) The Federal Government invests approximately $170 billion
    annually in research and development.
    (2) Systematic replication efforts have found that a
    substantial proportion of published research findings,
    including findings from federally funded research, cannot
    be independently reproduced or replicated.
    (3) The estimated annual cost of irreproducible preclinical
    research in the United States exceeds $28 billion.
    (4) Irreproducible research delays medical treatments,
    misallocates scarce resources, and undermines public
    trust in science.
    (5) Evidence-based practices, including pre-registration of
    studies, data and code sharing, and enhanced methods
    reporting, can substantially improve the reliability of
    research findings.
(b) PURPOSE.--The purpose of this Act is to improve the
reliability and transparency of federally funded research by
establishing reproducibility standards, requiring transparency
practices, and creating accountability mechanisms.

SEC. 3. DEFINITIONS.

In this Act:
(1) CONFIRMATORY RESEARCH.--The term "confirmatory research"
means research designed to test a pre-specified hypothesis
using pre-specified methods and analysis plans.
(2) COVERED AGENCY.--The term "covered agency" means any
Federal agency that funds extramural research, including the
National Institutes of Health, the National Science Foundation,
the Department of Energy, the Department of Defense, and such
other agencies as the Director of the Office of Science and
Technology Policy may designate.
(3) EXPLORATORY RESEARCH.--The term "exploratory research"
means research conducted without pre-specified hypotheses for
the purpose of generating hypotheses, discovering patterns,
or developing new methods.
(4) PRE-REGISTRATION.--The term "pre-registration" means the
practice of publicly registering the hypotheses, methods,
and analysis plan of a study on an approved registry before
data collection or, in the case of secondary data analysis,
before data analysis begins.
(5) REPRODUCIBILITY.--The term "reproducibility" means the
ability of an independent researcher to obtain consistent
results using the same data, methods, and conditions of
analysis as the original study.
(6) REPLICABILITY.--The term "replicability" means the ability
of an independent researcher to obtain consistent results
using new data collection but following the same or
substantially similar methods as the original study.

SEC. 4. PRE-REGISTRATION REQUIREMENTS.

(a) IN GENERAL.--Not later than 2 years after the date of
enactment of this Act, each covered agency shall require that
all confirmatory research funded by the agency be pre-registered
on an approved public registry before data collection begins
or, in the case of secondary data analysis, before data
analysis begins.
(b) APPROVED REGISTRIES.--The Director of the Office of Science
and Technology Policy, in consultation with covered agencies,
shall maintain a list of approved pre-registration registries
that meet standards for public accessibility, time-stamping,
and permanence.
(c) CONTENTS OF PRE-REGISTRATION.--Each pre-registration
shall include, at a minimum:
    (1) the research question or hypothesis;
    (2) the study design and methods;
    (3) the primary outcome variables;
    (4) the planned sample size and basis for sample size
    determination;
    (5) the planned statistical analysis, including the
    statistical tests to be used and the criteria for
    interpreting results; and
    (6) the criteria for excluding data or observations.
(d) EXPLORATORY RESEARCH.--Nothing in this section shall
require pre-registration of exploratory research. Researchers
conducting exploratory research shall clearly label such
research as exploratory in any resulting publications.
(e) FLEXIBILITY.--Deviations from a pre-registered plan shall
be permitted provided that:
    (1) all deviations are disclosed in the resulting
    publication;
    (2) the original pre-registered analysis is also reported;
    and
    (3) any unplanned analyses are clearly labeled as
    exploratory.

SEC. 5. DATA AND CODE SHARING REQUIREMENTS.

(a) IN GENERAL.--Not later than 2 years after the date of
enactment of this Act, each covered agency shall require that
all research data and analysis code produced with Federal
funding be made publicly available at the time of publication
of results, subject to the exceptions in subsection (c).
(b) DATA MANAGEMENT PLANS.--Each application for Federal
research funding shall include a data management and sharing
plan that describes:
    (1) the types of data and code to be generated;
    (2) the standards and formats to be used;
    (3) the repository or repositories where data and code
    will be deposited;
    (4) the timeline for data sharing; and
    (5) any applicable access restrictions and their
    justification.
(c) EXCEPTIONS.--Data sharing requirements under this section
shall not apply where:
    (1) sharing would violate the privacy rights of research
    participants under the Health Insurance Portability and
    Accountability Act, the Family Educational Rights and
    Privacy Act, or other applicable privacy laws;
    (2) sharing would compromise national security;
    (3) sharing is prohibited by the terms of a data use
    agreement with a third-party data provider; or
    (4) the data cannot be practicably de-identified.
(d) PRIVACY PROTECTIONS.--Where data sharing is restricted
under subsection (c), the researcher shall:
    (1) provide access to de-identified or synthetic data
    sufficient for independent verification of primary
    analyses, where feasible;
    (2) describe the procedures used for de-identification;
    and
    (3) make restricted data available through a controlled-
    access mechanism for qualified researchers who agree to
    appropriate data use terms.

SEC. 6. METHODS REPORTING STANDARDS.

(a) IN GENERAL.--Not later than 2 years after the date of
enactment of this Act, the Director of the Office of Science
and Technology Policy, in consultation with covered agencies
and relevant professional organizations, shall develop and
promulgate minimum methods reporting standards for federally
funded research.
(b) CONTENTS.--Methods reporting standards shall require, at
a minimum:
    (1) complete description of experimental procedures
    sufficient for independent replication;
    (2) specification of all materials, reagents, equipment,
    and software used, including version numbers;
    (3) disclosure of all outcome variables measured;
    (4) reporting of all statistical analyses conducted,
    including those yielding non-significant results;
    (5) reporting of effect sizes, confidence intervals, and
    exact p-values for all statistical tests;
    (6) a priori power analysis or justification of sample
    size; and
    (7) use of discipline-appropriate reporting checklists.

SEC. 7. INSTITUTIONAL ACCOUNTABILITY.

(a) REPRODUCIBILITY OFFICERS.--Each institution receiving more
than $10,000,000 annually in Federal research funding shall
designate a Reproducibility and Research Integrity Officer
responsible for:
    (1) monitoring compliance with the requirements of this
    Act;
    (2) providing training to researchers on reproducibility
    practices;
    (3) reporting annually to the relevant covered agency on
    institutional compliance; and
    (4) investigating and addressing reproducibility concerns.
(b) COMPLIANCE AUDITS.--Each covered agency shall conduct
random compliance audits of at least 5 percent of funded
research projects annually, verifying that:
    (1) pre-registration requirements have been met;
    (2) data and code have been shared as required;
    (3) methods reporting standards have been followed; and
    (4) deviations from pre-registered plans have been
    disclosed.
(c) CONSEQUENCES OF NON-COMPLIANCE.--Covered agencies may
impose consequences for non-compliance, including:
    (1) requiring corrective action plans;
    (2) requiring additional training;
    (3) reducing future funding eligibility; and
    (4) in cases of repeated or willful non-compliance,
    suspending or debarring investigators or institutions
    from Federal funding.

SEC. 8. INTERAGENCY COORDINATION.

(a) INTERAGENCY WORKING GROUP.--The Director of the Office
of Science and Technology Policy shall establish an
Interagency Working Group on Research Reproducibility,
comprising representatives of each covered agency, to
coordinate implementation of this Act.
(b) REPORT TO CONGRESS.--Not later than 3 years after the
date of enactment of this Act, and every 2 years thereafter,
the Director shall submit to Congress a report on:
    (1) the status of implementation of this Act;
    (2) compliance rates across agencies and institutions;
    (3) the effect of reproducibility requirements on
    research quality, as measured by available evidence;
    (4) recommendations for improvements; and
    (5) an assessment of the costs and benefits of the
    requirements imposed by this Act.

SEC. 9. AUTHORIZATION OF APPROPRIATIONS.

There are authorized to be appropriated to carry out this Act
$50,000,000 for each of fiscal years 2027 through 2032, to
be allocated among covered agencies for implementation,
infrastructure, training, and compliance monitoring.

SEC. 10. EFFECTIVE DATE.

This Act shall take effect on the date of enactment, with
the requirements of Sections 4, 5, 6, and 7 taking effect
not later than 2 years after such date.
```

**Explanation**:

- **Section 2**: Establishes congressional findings documenting the scope and cost of the problem, providing the factual basis for legislative action
- **Section 3**: Defines key terms, importantly distinguishing between confirmatory and exploratory research to address concerns that pre-registration would stifle creativity
- **Section 4**: Requires pre-registration of confirmatory studies while explicitly exempting exploratory research. Allows deviations from pre-registered plans provided they are disclosed
- **Section 5**: Mandates data and code sharing with carefully constructed exceptions for privacy, national security, and third-party data agreements. Requires privacy-preserving alternatives when full sharing is not possible
- **Section 6**: Directs OSTP to develop methods reporting standards in consultation with the scientific community, avoiding overly prescriptive legislation
- **Section 7**: Creates institutional accountability through Reproducibility Officers and compliance audits, modeled on existing research integrity infrastructure
- **Section 8**: Ensures coordinated implementation across agencies
- **Sections 9-10**: Provides funding and a 2-year implementation timeline

**Potential Challenges**:

| Challenge | Response |
|-----------|----------|
| Academic freedom concerns | Exploratory research exempted; deviations from pre-registration permitted with disclosure |
| Compliance burden on researchers | 2-year phase-in; $50M authorization for infrastructure and training |
| Privacy conflicts with data sharing | Explicit exceptions; privacy-preserving alternatives required |
| Resistance from established investigators | Graduated enforcement; focus on training before penalties |
| Cost of implementation | $50M is less than 0.2% of irreproducible research costs ($28B) |

**Refinements**:

- **Stronger version**: Require registered reports for all confirmatory federally funded research
- **Fallback version**: Apply requirements only to NIH and NSF initially, expanding to other agencies after evaluation
- **Alternative approach**: Incentive-based rather than mandate-based: provide supplemental funding or priority consideration for applications that include pre-registration and data sharing commitments

---

### Bill 2: Scientific Transparency in Federally Funded Research Act

**Purpose**: Establish a National Replication Initiative to systematically verify influential research findings, create a public replication database, and incentivize replication as a valued research activity.

**Draft Text**:

```text
SEC. 1. SHORT TITLE.

This Act may be cited as the "Scientific Transparency in
Federally Funded Research Act".

SEC. 2. FINDINGS AND PURPOSE.

(a) FINDINGS.--Congress finds the following:
    (1) Replication of published research findings is essential
    for establishing the reliability of the scientific
    evidence base.
    (2) Current academic incentive structures discourage
    replication, resulting in fewer than 3 percent of
    published studies being independently replicated.
    (3) Systematic replication projects have revealed
    replication failure rates of 40 to 90 percent across
    scientific disciplines.
    (4) There is no sustained Federal investment in systematic
    replication of research findings despite the Federal
    Government being the largest funder of basic research.
    (5) A reliable evidence base is essential for sound public
    policy, effective medical treatments, and responsible
    stewardship of taxpayer funds.
(b) PURPOSE.--The purpose of this Act is to establish a
sustained Federal investment in the systematic replication
of influential research findings, create infrastructure
for recording and disseminating replication results, and
ensure that replication is recognized as a valuable
scientific contribution.

SEC. 3. DEFINITIONS.

In this Act:
(1) DIRECTOR.--The term "Director" means the Director of
the Office of Science and Technology Policy.
(2) INITIATIVE.--The term "Initiative" means the National
Replication Initiative established under section 4.
(3) PRIORITY FINDINGS.--The term "priority findings" means
published research findings that meet criteria established
under section 5, including high citation count, policy
relevance, clinical application, or influence on subsequent
research programs.

SEC. 4. NATIONAL REPLICATION INITIATIVE.

(a) ESTABLISHMENT.--There is established within the Office
of Science and Technology Policy a National Replication
Initiative to coordinate and fund the systematic replication
of influential scientific research.
(b) FUNCTIONS.--The Initiative shall:
    (1) coordinate replication activities across Federal
    agencies;
    (2) administer a competitive grant program for replication
    studies;
    (3) maintain the National Replication Database established
    under section 6;
    (4) develop and disseminate best practices for conducting
    and reporting replication studies;
    (5) publish an annual report on the state of replication
    across scientific disciplines; and
    (6) consult with the scientific community, including
    professional societies, journal editors, and
    international counterparts.
(c) ADVISORY BOARD.--The Director shall establish a National
Replication Advisory Board comprising:
    (1) representatives of each covered agency;
    (2) researchers with expertise in replication methodology;
    (3) journal editors;
    (4) representatives of industry;
    (5) representatives of patient advocacy organizations; and
    (6) at least 2 early-career researchers.
(d) COVERED AGENCY PARTICIPATION.--Each Federal agency that
funds extramural research shall:
    (1) designate a replication coordinator;
    (2) allocate not less than 3 percent of its extramural
    research budget to fund replication studies, either
    through the Initiative or through agency-specific
    programs; and
    (3) report annually to the Initiative on replication
    activities and findings.

SEC. 5. REPLICATION PRIORITY SETTING.

(a) CRITERIA.--The Advisory Board shall develop criteria for
identifying priority findings for replication, considering:
    (1) the influence of the finding on subsequent research,
    as measured by citation count and derivative work;
    (2) the relevance of the finding to public policy or
    regulatory decisions;
    (3) the clinical application of the finding, including
    use in treatment guidelines or drug development;
    (4) the theoretical importance of the finding within its
    discipline;
    (5) the availability of sufficient methodological detail
    to permit replication;
    (6) prediction market or expert survey assessments of
    replication probability; and
    (7) the cost and feasibility of replication.
(b) ANNUAL PRIORITY LIST.--The Advisory Board shall publish
annually a list of priority findings recommended for
replication, organized by discipline and priority level.
(c) PUBLIC INPUT.--The Advisory Board shall solicit public
input on replication priorities, including from researchers,
clinicians, policymakers, and the general public.

SEC. 6. NATIONAL REPLICATION DATABASE.

(a) ESTABLISHMENT.--The Initiative shall establish and
maintain a publicly accessible National Replication Database
containing:
    (1) records of all replication attempts funded by Federal
    agencies, including those that fail to replicate the
    original finding;
    (2) links to the original studies being replicated;
    (3) detailed methods and data from replication studies;
    (4) statistical comparisons between original and
    replication results; and
    (5) metadata enabling systematic analysis of replication
    rates across fields, methods, and institutions.
(b) ACCESSIBILITY.--The Database shall be freely accessible
to the public through a searchable online interface.
(c) INTEGRATION.--The Initiative shall seek to integrate the
Database with existing platforms, including the Open Science
Framework, PubMed, and discipline-specific databases.

SEC. 7. REPLICATION GRANTS.

(a) GRANT PROGRAM.--The Initiative shall administer a
competitive grant program to fund replication studies.
(b) ELIGIBILITY.--Grants shall be available to:
    (1) individual researchers or research teams at
    institutions of higher education;
    (2) Federal laboratories;
    (3) nonprofit research organizations; and
    (4) replication consortia comprising multiple institutions.
(c) PRIORITY.--In awarding grants, the Initiative shall
give priority to:
    (1) replication of findings on the annual priority list;
    (2) applications from early-career researchers;
    (3) applications proposing multi-site replication designs;
    and
    (4) applications that include plans for assessing boundary
    conditions and moderators.
(d) REPORTING.--Each grant recipient shall:
    (1) pre-register the replication study before data
    collection;
    (2) make all data and code publicly available upon
    completion;
    (3) submit results to the National Replication Database;
    and
    (4) submit results for publication in a peer-reviewed
    journal regardless of outcome.

SEC. 8. RECOGNITION OF REPLICATION.

(a) FEDERAL AGENCY RECOGNITION.--Each covered agency shall:
    (1) recognize replication studies as valuable scientific
    contributions in grant applications, progress reports,
    and career development awards;
    (2) include replication activity as a positive factor in
    evaluating investigators' track records; and
    (3) accept replication publications as evidence of
    scientific productivity in grant applications.
(b) INSTITUTIONAL GUIDANCE.--The Director shall issue guidance
to institutions of higher education recommending that:
    (1) replication studies be credited in hiring, tenure,
    and promotion decisions;
    (2) participation in replication projects be recognized
    in annual performance reviews; and
    (3) training in replication methodology be incorporated
    into graduate curricula.

SEC. 9. AUTHORIZATION OF APPROPRIATIONS.

(a) IN GENERAL.--There are authorized to be appropriated to
carry out this Act:
    (1) $25,000,000 for fiscal year 2027;
    (2) $50,000,000 for fiscal year 2028;
    (3) $75,000,000 for fiscal year 2029;
    (4) $100,000,000 for each of fiscal years 2030 through
    2032.
(b) AGENCY ALLOCATIONS.--Of the amounts allocated by each
covered agency under section 4(d)(2), not less than
50 percent shall be used for grants under section 7.

SEC. 10. EFFECTIVE DATE.

(a) IN GENERAL.--This Act shall take effect on the date of
enactment.
(b) IMPLEMENTATION.--The Initiative shall be fully operational
not later than 18 months after the date of enactment.
```

**Explanation**:

- **Section 4**: Creates the National Replication Initiative as a coordinating body within OSTP, avoiding the creation of a new independent agency while ensuring cross-agency coordination
- **Section 4(d)(2)**: The 3% set-aside is the core mechanism, directing approximately $5 billion annually (3% of the estimated $170 billion federal R&D budget) toward replication. This is far more than any existing replication effort but still a small fraction of overall research spending
- **Section 5**: Establishes a systematic, evidence-based process for identifying which findings should be replicated, incorporating both quantitative metrics and expert judgment
- **Section 6**: Creates a permanent public record of replication results, addressing the current problem that replication attempts are scattered across journals and often unpublished
- **Section 7**: The grant program creates a professional pathway for replication work, with priority for early-career researchers
- **Section 8**: Directly addresses the incentive problem by directing agencies to recognize replication in career evaluation

**Potential Challenges**:

| Challenge | Response |
|-----------|----------|
| 3% set-aside reduces funding for new research | 3% is modest; unreliable research wastes far more resources |
| Agency resistance to earmarking | Phase-in schedule; agencies retain flexibility in implementation |
| Difficulty identifying replication priorities | Advisory Board with diverse expertise; public input process |
| Researcher reluctance to replicate others' work | Grant funding, career recognition, and priority for early-career |
| Political opposition to new spending | Net savings from reducing irreproducible research; bipartisan accountability appeal |

**Refinements**:

- **Stronger version**: Require 5% set-aside; mandate that no federal grant over $1 million be awarded without a replication component
- **Fallback version**: Pilot at NIH and NSF only; 1% set-aside with provisions for increase based on evaluation
- **Alternative approach**: Create replication requirements within existing grant programs rather than a separate initiative

## State Model Legislation

### Model State Research Transparency Act

**Purpose**: Require state-funded research at public universities to adopt reproducibility best practices and create state-level incentives for transparent research.

**Draft Text**:

```text
SECTION 1. SHORT TITLE.

This Act may be cited as the "[State] Research Transparency
Act".

SECTION 2. DEFINITIONS.

(a) "Covered research" means research funded in whole or
in part by state appropriations to institutions of higher
education.
(b) "Pre-registration" means the public registration of
research hypotheses, methods, and analysis plans before
data collection.
(c) "Open data" means making research data publicly
available in a machine-readable format.

SECTION 3. REQUIREMENTS.

(a) Each public institution of higher education receiving
state research funding shall:
    (1) adopt a policy encouraging pre-registration of
    confirmatory research;
    (2) maintain a publicly accessible repository for
    research data produced with state funding;
    (3) include reproducibility and transparency practices
    in the evaluation of faculty for hiring, tenure, and
    promotion; and
    (4) provide training in reproducibility practices for
    graduate students and research faculty.
(b) The [state higher education board] shall report annually
to the legislature on institutional compliance with this
section.

SECTION 4. INCENTIVES.

The [state higher education board] may establish awards for
excellence in research reproducibility and transparency,
funded from existing appropriations.

SECTION 5. EFFECTIVE DATE.

This Act shall take effect on [date], with compliance
required within 2 years of the effective date.
```

**Explanation**: This model legislation is intentionally lighter than the federal bills, using encouragement and reporting rather than mandates. State legislatures have less authority over research methodology than federal funders, and a lighter touch is more likely to gain acceptance from university systems.

**Adaptations**: States with larger public university systems (California, Texas, New York) might adopt more detailed requirements. States with smaller systems might focus on training and reporting rather than infrastructure.

## Regulatory Framework

### OSTP Guidance on Reproducibility Standards

**Existing Authority**: The Office of Science and Technology Policy has authority under the National Science and Technology Policy, Organization, and Priorities Act of 1976 (42 U.S.C. Section 6601 et seq.) to coordinate science and technology policy across federal agencies.

**Draft Regulation**: OSTP should issue a memorandum to heads of federal agencies directing:

1. All agencies funding extramural research to require pre-registration of confirmatory studies by 2028
2. All agencies to require data management and sharing plans consistent with the NIH Data Management and Sharing Policy by 2028
3. All agencies to develop discipline-appropriate methods reporting standards by 2029
4. All agencies to allocate a minimum percentage of extramural research budgets to replication studies by 2029

**Explanation**: Executive action through OSTP can achieve many of the goals of the proposed legislation without congressional action, though with less permanence and enforcement authority.

### NIH Policy Enhancement

**Existing Authority**: 42 U.S.C. Section 282(b)(12) directs the NIH Director to ensure research integrity. The 2023 Data Management and Sharing Policy provides a model for additional requirements.

**Proposed Enhancement**: NIH should strengthen its existing reproducibility requirements by:

1. Requiring pre-registration for all confirmatory research funded by NIH, with compliance verified at progress report
2. Requiring that all NIH-funded studies report effect sizes, confidence intervals, and power analyses
3. Establishing a dedicated replication funding mechanism within each Institute and Center
4. Including reproducibility track record as a review criterion for investigator qualifications

## Legal Considerations

### Constitutional Issues

The proposed legislation operates through Congress's spending power, conditioning federal research funding on compliance with reproducibility requirements. This approach is well-established constitutionally. The Supreme Court has upheld conditions on federal spending so long as they are: (1) in pursuit of the general welfare, (2) unambiguous, (3) related to the purpose of the federal spending, and (4) not independently unconstitutional. *South Dakota v. Dole*, 483 U.S. 203 (1987). Reproducibility requirements clearly meet all four criteria.

### Academic Freedom

The proposed legislation does not restrict what researchers may study or what conclusions they may reach. It requires only that the methods and data underlying publicly funded research be transparent and verifiable. This is analogous to existing requirements for human subjects review (IRB), financial disclosure, and data management---all of which have been accepted as legitimate conditions of federal funding without infringing academic freedom.

### Preemption Questions

The federal legislation does not preempt state action. States remain free to adopt additional reproducibility requirements for state-funded research. The model state legislation is complementary to, not in conflict with, the proposed federal bills.

### Enforcement Mechanisms

Enforcement relies on existing mechanisms for federal grant compliance: institutional assurances, progress reports, audit authority, and the ability to suspend or debar non-compliant investigators or institutions. The creation of Reproducibility Officers at major institutions adds an institutional layer of accountability.

### Sunset and Review Provisions

Both federal bills include reporting requirements that create built-in review opportunities. Section 8(b) of the Research Reproducibility and Integrity Act requires biennial reports to Congress on implementation and effectiveness. The appropriation authorizations in both bills expire after 6 years, requiring congressional reauthorization and providing an opportunity for legislative refinement based on evidence.

## Loopholes, Shortcomings, and Rectification

### Research Reproducibility and Integrity Act

#### Potential Loopholes

| Loophole | Description | Severity |
|----------|-------------|----------|
| Vague pre-registration | Researchers could pre-register with overly broad hypotheses and flexible analysis plans, preserving analytical flexibility | High |
| Exploratory exemption abuse | Researchers could label confirmatory work as "exploratory" to avoid pre-registration requirements | High |
| De minimis data sharing | Sharing minimally processed data without adequate documentation renders it unusable for verification | Medium |
| Institutional capture of compliance | Reproducibility Officers could be installed without authority or resources, creating symbolic compliance | Medium |
| Audit rate insufficiency | 5% annual audit rate may be too low to create meaningful deterrence | Medium |

#### Shortcomings

| Issue | Impact | Root Cause |
|-------|--------|------------|
| Does not address publication bias directly | Journals may still preferentially publish significant results from pre-registered studies | Legislation targets researchers and funders, not private publishers |
| Does not reform tenure and hiring criteria | Universities may comply with letter of law without changing evaluation incentives | Federal spending power does not directly reach university personnel decisions |
| Limited to federally funded research | Privately funded research, which is substantial, is unaffected | Constitutional limits on federal regulatory authority over private activity |
| Does not address statistical reform | Researchers may continue using NHST with p < 0.05 even with better reporting | Legislation establishes reporting requirements, not methodological mandates |

#### Rectification Procedures

1. **Strengthen pre-registration standards**: OSTP should develop detailed pre-registration templates with required specificity levels for hypotheses, sample sizes, and analysis plans. Registrations failing to meet specificity requirements should be returned for revision before approval
2. **Audit exploratory classifications**: Compliance audits should specifically review whether studies classified as exploratory contain hallmarks of confirmatory research (specific directional hypotheses, statistical significance tests)
3. **Data documentation standards**: Require that shared data include machine-readable metadata, codebooks, and analysis scripts sufficient for independent replication
4. **Reproducibility Officer standards**: Issue minimum qualifications, authority, and reporting requirements for Reproducibility Officers to prevent symbolic appointments
5. **Increase audit rates**: Phase in higher audit rates (10-15%) as infrastructure develops, with risk-based targeting of institutions or investigators with past compliance issues

### Scientific Transparency in Federally Funded Research Act

#### Potential Loopholes

| Loophole | Description | Severity |
|----------|-------------|----------|
| Budget gaming | Agencies could count existing research as "replication" to meet the 3% set-aside without conducting genuine replications | High |
| Priority list manipulation | The advisory board could be influenced to exclude politically or commercially sensitive findings from the priority list | Medium |
| Selective replication | Researchers could choose to replicate only findings that are likely to replicate, inflating apparent replication rates | Medium |
| Career penalty persistence | Despite recognition provisions, replication work may still carry informal career stigma | Medium |

#### Shortcomings

| Issue | Impact | Root Cause |
|-------|--------|------------|
| 3% set-aside may be insufficient | At $5 billion, still covers only a fraction of influential findings | Political feasibility constraints on initial authorization |
| Advisory Board composition | May not adequately represent all disciplines or career stages | Fixed statutory composition |
| No mandate for publication of replication results | Journals may still decline to publish replication studies | Cannot mandate private publisher behavior |
| International coordination gaps | U.S.-only initiative may miss influential findings published abroad | Jurisdictional limits |

#### Rectification Procedures

1. **Define "replication" strictly**: OSTP should issue guidance defining what qualifies as replication expenditure, excluding routine research that does not constitute genuine independent replication
2. **Conflict-of-interest rules for Advisory Board**: Board members should be prohibited from voting on priority listings involving their own published work or direct competitors
3. **Pre-registration of replications**: Require that all funded replications be pre-registered, with analysis plans reviewed before data collection, to prevent selective replication
4. **Partner with journals**: Negotiate agreements with major publishers to accept replication results funded by the Initiative, potentially as a condition of government subscription purchases

### General Implementation Concerns

#### Systemic Issues

| Issue | Proposed Solution |
|-------|------------------|
| Compliance burden on small institutions | Provide technical assistance and shared infrastructure through regional consortia |
| Training gaps for current researchers | Fund transitional training programs through professional societies |
| Interagency coordination complexity | Designate a single OSTP official as reproducibility coordinator with cross-agency authority |
| Measuring reform effectiveness | Establish baseline replication rates before implementation to enable before-after comparison |

#### Sunset and Review Provisions

Both bills authorize appropriations for 6 years (fiscal years 2027-2032). Before reauthorization, Congress should:

1. Commission NASEM to evaluate the effectiveness of implemented reforms
2. Assess whether replication rates have improved relative to baseline
3. Evaluate the compliance burden on researchers and institutions
4. Determine whether the authorized funding levels are adequate
5. Consider expanding requirements to additional agencies or research categories based on evidence

## References

- 42 U.S.C. Section 282 (NIH Director authorities)
- 42 U.S.C. Section 6601 et seq. (National Science and Technology Policy, Organization, and Priorities Act)
- *South Dakota v. Dole*, 483 U.S. 203 (1987)
- National Academies of Sciences, Engineering, and Medicine. *Reproducibility and Replicability in Science*. Washington, DC: National Academies Press, 2019.
- National Institutes of Health. "Final NIH Policy for Data Management and Sharing." *Federal Register* (2020).
- Freedman, Leonard P., Iain M. Cockburn, and Timothy S. Simcoe. "The Economics of Reproducibility in Preclinical Research." *PLOS Biology* 13, no. 6 (2015): e1002165.
- Nosek, Brian A., et al. "Promoting an Open Research Culture." *Science* 348, no. 6242 (2015): 1422-1425.

## Related Topics

- [Open Science](../open-science/01-overview.md) - Broader open science policies and practices
- [Scientific Integrity](../scientific-integrity/01-overview.md) - Research misconduct and fraud
- [Peer Review](../peer-review/01-overview.md) - The peer review system and its reform
- [Research Funding](../research-funding/01-overview.md) - Federal research funding structures
- [Research Ethics](../research-ethics/01-overview.md) - Ethical conduct of research

## Document Navigation

- Previous: [Actions](10-actions.md)
- Up: [Science](../01-overview.md)
- Next: [Perspectives](12-perspectives.md)
