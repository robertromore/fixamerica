# Reproducibility: Stakeholders

## Overview

The reproducibility crisis affects a broad range of stakeholders, from individual researchers whose careers are shaped by publication incentives to the general public whose health and welfare depend on reliable scientific evidence. Understanding who is affected, who has power, and who benefits from the status quo is essential for designing reforms that can gain sufficient support to succeed.

## Primary Stakeholders

### Researchers (Early Career)

**Who they are**: Graduate students, postdoctoral fellows, and pre-tenure faculty constitute the majority of the research workforce. They conduct most of the day-to-day research and are most vulnerable to career pressures.

**How they are affected**:

- Face intense pressure to publish novel, significant findings to secure jobs and tenure
- Bear the highest career risk from adopting reproducibility practices that may slow publication output
- Most likely to be conducting the underpowered, exploratory studies that contribute to the crisis
- Least able to push back against advisors or institutional norms that reward quantity over rigor

**Their power**: Limited individually, but collectively significant. Early-career researchers are the primary audience for reform efforts and, as they advance into leadership positions, will determine whether reforms persist.

**Their interests**: Job security, career advancement, professional recognition. Many early-career researchers support reproducibility reform in principle but face rational incentives to prioritize publication volume.

### Researchers (Senior and Established)

**Who they are**: Tenured faculty, department chairs, lab directors, and senior investigators. They hold institutional power and set norms for their fields and trainees.

**How they are affected**:

- Their reputations may be challenged by replication failures of their published work
- They control hiring, tenure, and promotion decisions that shape incentives for junior researchers
- They serve as journal editors, grant reviewers, and members of professional organizations that set norms
- Some have built careers on findings that may not replicate

**Their power**: Substantial. Senior researchers control the gatekeeping functions of science: peer review, hiring, funding allocation, and editorial decisions.

**Their interests**: Maintaining professional reputation, securing continued funding, advancing their research programs. Some are committed reformers; others resist changes that may devalue their published record.

### Patients and Research Subjects

**Who they are**: Individuals who participate in clinical trials, receive treatments based on published research, or are affected by public health policies informed by scientific evidence.

**How they are affected**:

- Failed replications in biomedicine mean that drugs and treatments advanced to clinical trials based on irreproducible preclinical findings may be ineffective or harmful
- The estimated $28 billion wasted annually on irreproducible preclinical research represents delayed treatments and diverted resources
- Patients in clinical trials of treatments based on irreproducible evidence are exposed to risk without corresponding benefit
- Public health policies built on unreliable evidence may be ineffective or counterproductive

**Their power**: Very limited in the research system. Patients do not participate in decisions about research methodology, journal policies, or academic incentives.

**Their interests**: Effective treatments, safety, and efficient use of research resources.

### Federal Funding Agencies

**Who they are**: NIH, NSF, DARPA, DOE, and other agencies that fund the majority of basic research in the United States. NIH alone has an annual budget of approximately $47 billion.

**How they are affected**:

- Irreproducible research represents a massive misallocation of public funds
- Agency credibility depends on funding research that produces reliable knowledge
- Agencies face congressional scrutiny over the return on public investment in research

**Their power**: Enormous. Funding agencies can require data sharing, pre-registration, power analyses, and reproducibility practices as conditions of grant funding. NIH's 2023 Data Management and Sharing Policy demonstrates this power.

**Their interests**: Maximizing the impact and reliability of publicly funded research, maintaining public and congressional support for research budgets.

### Scientific Publishers and Journals

**Who they are**: Commercial publishers (Elsevier, Springer Nature, Wiley), professional society publishers (APA, AAAS, ACS), and open-access publishers (PLOS, MDPI, Frontiers). Major journals include *Nature*, *Science*, *Cell*, *The Lancet*, and *New England Journal of Medicine*.

**How they are affected**:

- Journal credibility depends on publishing reliable research
- High-profile retractions and replication failures damage journal reputations
- Reproducibility policies (data sharing requirements, registered reports) require editorial and operational changes
- The business model of traditional publishing (subscription-based access to novel findings) may be disrupted by open science

**Their power**: Substantial. Journals control what gets published, which determines what gets rewarded in the academic system. Their policies on data sharing, pre-registration, and methods reporting directly shape researcher behavior.

**Their interests**: Maintaining prestige, readership, and revenue. This can conflict with reproducibility: prestigious journals are prestigious partly because they publish surprising, high-impact findings, which are exactly the findings most likely to be false positives.

## Secondary Stakeholders

### Universities and Research Institutions

**How they are affected**: Institutional reputation depends on research quality; irreproducible findings that are later retracted damage institutional credibility. Universities also bear responsibility for training the next generation of researchers in rigorous practices.

**Their power**: Institutions control hiring, tenure, and promotion criteria. They can incentivize reproducibility by valuing rigor, replication, and open science in personnel decisions.

**Their interests**: Prestige, rankings, grant revenue, patent income. Current metrics (publication counts, grant dollars, citations) do not capture research reliability.

### Pharmaceutical and Biotechnology Industry

**How they are affected**: Industry relies on published academic research as the basis for drug development pipelines. When preclinical findings cannot be reproduced, industry wastes resources on development programs built on unreliable foundations. Both Amgen and Bayer have publicly documented the high failure rates they encounter when attempting to validate academic findings.

**Their power**: Industry can exert pressure on academic standards through its role as a consumer of academic research and as a funder of academic-industry partnerships.

**Their interests**: Reliable preclinical findings that translate to successful drug development, reducing the cost and failure rate of R&D pipelines.

### The General Public and Taxpayers

**How they are affected**: The public funds research through taxes and depends on reliable science for health care, environmental policy, technology, and evidence-based policymaking. Irreproducible research wastes public funds and can lead to policies based on faulty evidence.

**Their power**: Indirect, through elected representatives and public opinion. Public trust in science is a crucial resource that the reproducibility crisis undermines.

**Their interests**: Effective use of public funds, reliable scientific evidence for policy decisions, trustworthy health care and technology.

### Professional Societies and Standards Bodies

**Who they are**: Organizations like the American Psychological Association (APA), American Statistical Association (ASA), American Medical Association (AMA), and National Academies of Sciences, Engineering, and Medicine (NASEM).

**How they are affected**: These organizations set ethical standards, reporting guidelines, and professional norms for their fields. The reproducibility crisis challenges them to update standards and practices.

**Their power**: Significant. Professional societies can change reporting standards, endorse new statistical practices, and influence member behavior through guidelines, training, and credentialing.

**Their interests**: Maintaining the credibility and standards of their disciplines, serving their members' professional interests.

### Reproducibility Reform Organizations

**Who they are**: The Center for Open Science (COS), the Berkeley Initiative for Transparency in the Social Sciences (BITSS), the Institute for Replication, the EQUATOR Network, the Meta-Research Innovation Center at Stanford (METRICS), and similar organizations.

**How they are affected**: These organizations exist specifically to address the reproducibility crisis. Their success depends on the adoption of reforms by researchers, journals, and funders.

**Their power**: Growing. COS has been particularly effective in creating infrastructure (OSF), developing standards (TOP Guidelines), and promoting practices (registered reports, badges). However, their influence depends on voluntary adoption.

**Their interests**: Advancing open science and reproducibility practices, demonstrating the effectiveness of reforms, securing sustainable funding.

### Congress and Policymakers

**How they are affected**: Policymakers rely on scientific evidence for legislation and regulation. Irreproducible research undermines evidence-based policymaking and represents a poor return on public investment in research.

**Their power**: Congress controls federal research budgets and can mandate reproducibility practices through legislation or appropriations language.

**Their interests**: Accountability for public spending, evidence-based policy, maintaining public trust in government-funded science.

## Stakeholder Alignment

| Stakeholder | Supports Reform | Neutral | Resists Reform |
|-------------|----------------|---------|----------------|
| Early-career researchers | Support in principle; constrained by incentives | | Career risk of adoption |
| Senior researchers | Reformers in some fields | Many uninvolved | Those whose findings face replication challenge |
| Patients and public | Strong support for reliable science | | |
| Federal funders (NIH, NSF) | Active reform policies | | Resistance to mandates from funded investigators |
| Journals (reform-oriented) | Registered reports, TOP Guidelines | | Business model concerns |
| Journals (traditional) | | | Revenue from novelty-driven publishing model |
| Universities | Rhetoric of support | | Slow to change hiring/tenure criteria |
| Industry (pharma/biotech) | Support for reliable preclinical science | | Proprietary data concerns |
| Professional societies | Endorsement of guidelines | Slow organizational change | |
| Congress | Interest in accountability | Low issue salience | |
| Reform organizations (COS, BITSS) | Core mission | | |

## Power Dynamics

The reproducibility reform movement faces a fundamental collective action problem. Individual researchers bear the costs of adopting more rigorous practices (slower publication, smaller effect sizes, less exciting results) while the benefits accrue to the scientific system as a whole. Those with the most power to change incentives---senior researchers, journal editors, funding agencies, and university administrators---often have the least personal incentive to do so, because the current system has rewarded them.

Progress has come primarily through:

- **Top-down mandates**: Funder requirements (NIH data sharing policy) that apply to all grantees
- **Infrastructure creation**: Tools like OSF that make good practices easier
- **Normative change**: Shifting professional expectations through guidelines, badges, and visibility
- **Grassroots advocacy**: Early-career researchers and reform organizations pushing for change

The most effective reforms have been those that align individual incentives with system-level goals---for example, registered reports, which guarantee publication regardless of results, removing the incentive to p-hack.

## References

- Nosek, Brian A., et al. "Promoting an Open Research Culture." *Science* 348, no. 6242 (2015): 1422-1425.
- Freedman, Leonard P., Iain M. Cockburn, and Timothy S. Simcoe. "The Economics of Reproducibility in Preclinical Research." *PLOS Biology* 13, no. 6 (2015): e1002165.
- Smaldino, Paul E., and Richard McElreath. "The Natural Selection of Bad Science." *Royal Society Open Science* 3, no. 9 (2016): 160384.
- National Academies of Sciences, Engineering, and Medicine. *Reproducibility and Replicability in Science*. Washington, DC: National Academies Press, 2019.
- Begley, C. Glenn, and Lee M. Ellis. "Raise Standards for Preclinical Cancer Research." *Nature* 483, no. 7391 (2012): 531-533.

## Document Navigation

- Previous: [Root Causes](04-root-causes.md)
- Up: [Science](../01-overview.md)
- Next: [Opposition](06-opposition.md)
