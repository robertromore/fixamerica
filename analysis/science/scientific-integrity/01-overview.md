# Scientific Integrity: Overview

## Executive Summary

Scientific integrity -- the commitment to honesty, rigor, and transparency in the production and communication of research -- is the foundation upon which public trust in science rests. When researchers fabricate data, falsify results, or plagiarize the work of others, the consequences extend far beyond individual careers: flawed research can misdirect public health policy, waste billions in follow-up studies built on false premises, and erode the credibility of the entire scientific enterprise.

The U.S. federal government has invested in research integrity infrastructure since the 1980s, primarily through the Office of Research Integrity (ORI) within the Department of Health and Human Services. ORI oversees investigations of fabrication, falsification, and plagiarism (FFP) in research funded by the Public Health Service, including the National Institutes of Health. Yet the system faces mounting challenges: the volume of retractions has increased more than tenfold since 2000, sophisticated paper mills produce thousands of fraudulent manuscripts annually, image manipulation has become endemic in some fields, and whistleblowers who report misconduct often face devastating retaliation with little legal protection.

The current integrity framework was designed for a research ecosystem that has since been transformed by hypercompetitive funding environments, publish-or-perish career pressures, globalized collaboration, and artificial intelligence tools that can both detect and generate fraud. The system suffers from chronic underfunding, jurisdictional gaps, slow investigation timelines, and weak enforcement mechanisms. Most research misconduct is never detected, and when it is, sanctions are often inadequate to deter future violations.

Strengthening scientific integrity requires coordinated reform across federal oversight, institutional governance, journal policies, whistleblower protections, and research culture. The stakes are high: in an era of declining public trust in institutions, the credibility of science depends on demonstrating that the research enterprise takes honesty as seriously as it takes discovery.

## Scope

### What This Topic Covers

- **Research misconduct**: Fabrication, falsification, and plagiarism (FFP) as defined by federal policy
- **Office of Research Integrity (ORI)**: Structure, jurisdiction, investigation procedures, and enforcement
- **Institutional oversight**: Research integrity officers, institutional investigation processes, and compliance
- **Retraction and correction**: Journal retraction processes, the role of Retraction Watch, and post-publication review
- **Image and data manipulation**: Detection tools, prevalence, and prevention
- **Paper mills**: Commercial operations producing fraudulent manuscripts at scale
- **Predatory journals**: Publishers that undermine quality standards through pay-to-publish models
- **Whistleblower protections**: Legal safeguards for those who report misconduct
- **Research culture and incentives**: How career pressures contribute to integrity failures
- **International dimensions**: Cross-border misconduct, coordination with foreign integrity bodies

### What This Topic Does Not Cover

- **Peer review reform**: Covered in [Peer Review](../peer-review/01-overview.md)
- **Open science and data sharing**: Covered in [Open Science](../open-science/01-overview.md)
- **Reproducibility crisis broadly**: Covered in [Reproducibility](../reproducibility/01-overview.md)
- **Research ethics (human subjects, animal welfare)**: Covered in [Research Ethics](../research-ethics/01-overview.md)
- **Science communication and misinformation**: Covered in [Science Communication](../science-communication/01-overview.md)
- **Research funding structures**: Covered in [Research Funding](../research-funding/01-overview.md)

## Key Facts

| Metric | Value | Context |
|--------|-------|---------|
| Annual retractions worldwide | ~10,000+ | Up from fewer than 100 in 2000 |
| ORI findings of misconduct (annual avg) | ~10-12 cases | Despite thousands of allegations received |
| ORI annual budget | ~$9 million | Unchanged in real terms for over a decade |
| ORI staff | ~25 | Down from peak of ~35 |
| Average ORI investigation duration | 2-3 years | Some cases take 5+ years |
| Estimated misconduct prevalence | 1-2% of researchers | Based on meta-analyses of self-report surveys |
| Estimated "questionable research practices" | 10-35% of researchers | Including selective reporting, p-hacking |
| Paper mill output (estimated annual) | 10,000-50,000 papers | Growing rapidly, concentrated in biomedical fields |
| Retraction Watch database entries | 50,000+ | Cumulative tracked retractions since 1970s |
| Cost of a single misconduct investigation | $500,000-$2 million | Including institutional and federal costs |

## Key Tensions

### Detection vs. Due Process

Aggressive fraud detection is essential for protecting the integrity of the research record, but accused researchers have legitimate due process rights. Investigations can take years, during which allegations may leak and destroy careers even before findings are issued. Balancing thorough investigation with timely resolution and fairness to the accused is a persistent challenge.

### Institutional Self-Policing vs. Independent Oversight

Federal policy assigns primary investigation responsibility to the institutions that employ the accused researcher. This creates inherent conflicts of interest: universities have financial and reputational incentives to minimize findings of misconduct. Yet fully federalizing investigations would overwhelm an already under-resourced ORI and might violate principles of academic self-governance.

### Narrow vs. Broad Definitions of Misconduct

The federal definition of research misconduct is limited to FFP -- fabrication, falsification, and plagiarism. Many harmful practices fall outside this definition: selective reporting, p-hacking, gift authorship, failure to disclose conflicts of interest, and harassment that distorts research outcomes. Broadening the definition could capture more harmful behavior but risks criminalizing honest mistakes or differences of scientific judgment.

### Punishment vs. Prevention

The current system emphasizes detecting and punishing misconduct after it occurs. Critics argue that more resources should be devoted to prevention through training, mentoring, culture change, and reducing the perverse incentives that drive misconduct. The debate mirrors broader criminal justice questions about deterrence versus systemic reform.

### Transparency vs. Privacy

Public disclosure of misconduct findings serves the interest of correcting the scientific record and deterring future fraud. However, premature disclosure of unproven allegations can destroy the careers of innocent researchers. Balancing the public's right to know with individual privacy rights is a recurring tension.

## Subtopic Relationships

- **Peer Review** -- Peer review is the primary quality gate that integrity failures bypass; reforms to each system affect the other
- **Reproducibility** -- Integrity failures are a major driver of the reproducibility crisis; strengthening integrity improves reproducibility
- **Research Ethics** -- Misconduct investigations sometimes overlap with ethics violations involving human or animal subjects
- **Open Science** -- Transparency requirements (data sharing, preregistration) serve as structural integrity safeguards
- **Research Funding** -- Hypercompetitive funding environments create pressure to cut corners; funding reform reduces misconduct incentives
- **Science Communication** -- High-profile misconduct cases undermine public trust in science and fuel anti-science movements

## Document Navigation

- Next: [Current State](02-current-state.md)
- Up: [Science](../01-overview.md)
