# Scientific Integrity: History

## Early Foundations (Pre-1970s)

### The Ideal of Self-Correction

The modern scientific enterprise was built on the assumption that science is self-correcting. The norms articulated by sociologist Robert K. Merton in 1942 -- communalism, universalism, disinterestedness, and organized skepticism (CUDOS) -- described an idealized scientific community in which fraud would be detected and corrected through replication, peer review, and communal scrutiny.

For most of the twentieth century, research misconduct was treated as an aberration -- the work of isolated bad actors rather than a systemic problem. Major fraud cases were rare and shocking:

- **William Summerlin (1974)**: A researcher at Sloan Kettering Memorial Cancer Center who painted dark patches on white mice to simulate successful skin grafts, one of the first modern misconduct cases to receive wide attention
- **Cyril Burt (1970s, posthumous)**: British psychologist accused of fabricating twin study data supporting hereditary intelligence; the case remains debated

### Limited Institutional Response

Before the 1980s, research institutions had no formal procedures for investigating misconduct. Cases were handled informally -- often quietly, to protect institutional reputation. There was no federal definition of misconduct, no oversight body, and no systematic retraction process.

## The Congressional Era (1981-1992)

### The Cases That Forced Action

A series of high-profile misconduct cases in the early 1980s forced Congress to confront the absence of systematic oversight:

- **John Darsee (1981)**: A Harvard Medical School researcher found to have fabricated data in more than 100 published papers on cardiac research. Harvard's slow and inadequate internal investigation became a case study in institutional failure
- **Mark Spector (1981)**: A Cornell graduate student who fabricated results on a proposed cancer pathway, exposing weaknesses in laboratory supervision
- **Robert Slutsky (1980s)**: A University of California San Diego radiologist who fabricated or falsified data in approximately 60 publications over seven years

### Congressional Investigations

Representative Albert Gore Jr. held hearings in 1981 that first brought research misconduct to national attention. Representative John Dingell (D-MI) subsequently became the most aggressive congressional investigator of scientific fraud, holding a series of hearings throughout the 1980s and early 1990s.

**Key congressional actions:**

| Year | Action | Significance |
|------|--------|--------------|
| 1981 | Gore subcommittee hearings | First congressional attention to research fraud |
| 1985 | Health Research Extension Act | Required institutions receiving PHS funds to establish procedures for investigating misconduct; created precursor to ORI |
| 1986 | NSF creates Inspector General | Established misconduct oversight for NSF-funded research |
| 1989 | Creation of the Office of Scientific Integrity (OSI) | First dedicated federal misconduct office, under NIH |
| 1989 | Creation of the Office of Scientific Integrity Review (OSIR) | Appellate body within HHS |
| 1992 | Reorganization creating ORI | Merged OSI and OSIR into the Office of Research Integrity under the Assistant Secretary for Health |

### The Baltimore Case

The most consequential and controversial misconduct investigation of this era involved David Baltimore, a Nobel laureate at MIT. In 1986, a postdoctoral researcher, Margot O'Toole, raised concerns about a 1986 paper in *Cell* co-authored by Baltimore and Thereza Imanishi-Kari. The ensuing investigation lasted nearly a decade:

- O'Toole's initial complaints were dismissed by MIT and Tufts
- Congressman Dingell's subcommittee took up the case
- The Secret Service conducted forensic analysis of laboratory notebooks
- OSI found Imanishi-Kari guilty of misconduct in 1991
- An HHS appeals board overturned the finding in 1996, criticizing investigatory procedures
- The case deeply divided the scientific community: some saw it as necessary accountability; others viewed it as political persecution

The Baltimore case had lasting effects on research integrity policy, leading to stronger due process protections for accused researchers and reinforcing scientists' suspicion of government oversight.

## Defining Misconduct (1990s)

### The Federal Definition Debate

Throughout the 1990s, a contentious debate raged over how to define research misconduct. The initial federal definition included "other serious deviations from accepted practices" alongside fabrication, falsification, and plagiarism. Scientists objected that this vague language could be used to criminalize differences of scientific judgment.

**Timeline of definitional evolution:**

| Year | Definition | Key Feature |
|------|-----------|-------------|
| 1989 | PHS regulation, 42 C.F.R. Part 50 Subpart A | Included "other serious deviations" |
| 1995 | Commission on Research Integrity (Ryan Commission) | Proposed broader definition including "misappropriation" |
| 1999 | OSTP proposed policy | Proposed narrowing to FFP only |
| 2000 | Federal Research Misconduct Policy (OSTP) | Adopted FFP-only definition; removed "other serious deviations" |
| 2005 | 42 C.F.R. Part 93 | Codified FFP definition in regulation |

The decision to limit the federal definition to fabrication, falsification, and plagiarism was a compromise. It reassured scientists that honest errors and differences of interpretation would not be prosecuted, but it left harmful practices like selective reporting, data dredging, and authorship abuse outside the formal misconduct framework.

### The Ryan Commission (1995)

The Commission on Research Integrity, chaired by Kenneth J. Ryan, proposed a broader approach that included "misappropriation" as a fourth category of misconduct and recommended stronger whistleblower protections. Its recommendations were largely rejected by the scientific community, which lobbied successfully for a narrower definition.

## ORI Maturation and Challenges (2000-2015)

### Building the System

With the FFP definition settled, ORI focused on building institutional capacity:

- Published model institutional policies for handling allegations
- Developed training programs in responsible conduct of research (RCR)
- Created the ORI case database for transparency
- Established the Research Integrity Officer (RIO) network at institutions
- Began annual Research Conference on Research Integrity

### Notable Cases

| Year | Case | Significance |
|------|------|--------------|
| 2002 | Jan Hendrik Schon (Bell Labs) | Fabricated data in multiple high-profile physics papers; revealed weaknesses in high-prestige journal review |
| 2005 | Hwang Woo-suk (South Korea) | Fabricated human embryonic stem cell cloning results; international scandal |
| 2005 | Eric Poehlman (University of Vermont) | First researcher imprisoned for misconduct (grant fraud); sentenced to 1 year |
| 2010 | Scott Reuben | Fabricated data in 21 studies on pain management; sentenced to 6 months |
| 2012 | Diederik Stapel (Netherlands) | Social psychologist who fabricated data for over a decade; 58+ retractions |
| 2014 | Haruko Obokata (RIKEN, Japan) | STAP cell fraud; led to retraction and suicide of co-author Yoshiki Sasai |

### Structural Weaknesses Exposed

By the mid-2010s, several systemic problems with the integrity infrastructure had become apparent:

- **Chronic underfunding**: ORI's budget remained stagnant despite growing caseloads and research expenditures
- **Slow timelines**: Investigations routinely took 3-5 years, during which fraudulent research continued to be cited
- **Institutional conflicts**: Universities had strong incentives to minimize findings or delay investigations
- **Limited jurisdiction**: ORI could only address PHS-funded misconduct; no equivalent body existed for most other agencies
- **Weak sanctions**: Debarment periods were typically 3-5 years, after which researchers could return to federally funded work
- **No criminal authority**: ORI could not pursue criminal charges; referrals to the Department of Justice were rare

## The Retraction Explosion and Paper Mills (2015-Present)

### Retraction Watch and Transparency

The founding of Retraction Watch in 2010 by Ivan Oransky and Adam Marcus marked a turning point in research integrity awareness. By systematically tracking and publicizing retractions, Retraction Watch transformed retractions from hidden corrections into public accountability events. The Retraction Watch Database, launched in 2018, made retraction data systematically searchable for the first time.

### The Paper Mill Threat

The emergence of large-scale paper mills in the mid-2010s represented a qualitative change in the integrity threat landscape:

- **2017-2018**: Researchers and integrity sleuths began identifying clusters of suspicious papers sharing telltale features: tortured phrases, recycled images, and template-like structures
- **2020**: Major publishers acknowledged the paper mill problem publicly for the first time
- **2022**: Wiley announced it would cease publishing in journals most compromised by paper mills
- **2023-2024**: Mass retractions of 10,000+ papers by Wiley alone; other publishers followed
- **2024-2025**: AI-generated papers began appearing, making detection increasingly difficult

### Elisabeth Bik and Citizen Science

Elisabeth Bik, a microbiologist who left her research career to focus on image integrity, became the most prominent independent integrity investigator. Her systematic screening of published papers for image manipulation, beginning around 2014, demonstrated both the prevalence of the problem and the inadequacy of institutional responses. Bik's work, often conducted via social media platforms like PubPeer, illustrated the potential and limitations of crowd-sourced integrity enforcement.

### The Francesca Gino Case (2023-Present)

The investigation into Harvard Business School professor Francesca Gino for alleged data fabrication in behavioral science research became one of the most closely watched integrity cases of the 2020s. The case, initially raised by the Data Colada blog, highlighted:

- The role of post-publication review and independent reanalysis
- The legal risks faced by whistleblowers (Gino sued the accusers for defamation)
- The slow pace of institutional investigation
- The tension between academic freedom and accountability
- The challenge of investigating senior tenured faculty

### The Dan Ariely Investigations

Duke behavioral economist Dan Ariely faced allegations of data fabrication in multiple studies, including a prominent paper on dishonesty. The irony of a dishonesty researcher accused of fabricating data drew public attention to broader questions about the reliability of social science research.

## Evolving Policy Landscape

### OSTP Actions

The White House Office of Science and Technology Policy has periodically updated federal integrity policies:

- **2000**: Federal Research Misconduct Policy establishing FFP definition
- **2023**: Updated guidance on scientific integrity for federal agencies, responding to concerns about political interference during prior administrations
- **2024-2025**: Ongoing discussions about modernizing 42 C.F.R. Part 93 to address new challenges

### The Role of AI

Artificial intelligence has created both new threats and new tools for integrity:

**Threats:**

- AI-generated text can produce manuscripts that pass plagiarism detection
- AI-generated images (synthetic microscopy, fabricated gel images) are increasingly realistic
- AI tools can generate realistic but fabricated datasets
- Chatbots can be used to manufacture peer review reports

**Tools:**

- AI-based image duplication and manipulation detection
- Natural language processing to identify tortured phrases and paper mill signatures
- Statistical forensics to detect fabricated datasets
- Machine learning to flag suspicious citation patterns and reference manipulation

## Lessons from History

1. **Self-correction is insufficient**: The assumption that science would police itself was never fully warranted and has become less tenable as the system has scaled
2. **Congressional intervention was necessary but imperfect**: Government oversight was essential to creating formal integrity mechanisms, but political involvement also created backlash and fear among scientists
3. **Narrow definitions create gaps**: Limiting misconduct to FFP was politically expedient but left harmful practices unaddressed
4. **Whistleblower protection remains the weakest link**: From Margot O'Toole to modern cases, those who report misconduct consistently suffer disproportionate consequences
5. **Technology changes the game**: Paper mills, AI, and digital manipulation have outpaced a regulatory framework designed for an analog era
6. **Institutional self-interest undermines accountability**: The conflict between institutional reputation and honest investigation has been a consistent theme since the earliest cases

## Document Navigation

- Previous: [Current State](02-current-state.md)
- Next: [Root Causes](04-root-causes.md)
- Up: [Science](../01-overview.md)
