# Research Ethics: Root Causes

## Overview

The persistent gaps and failures in the American research ethics system are not random. They emerge from identifiable structural dynamics, institutional incentives, and historical path dependencies. Understanding these root causes is essential for designing reforms that address underlying problems rather than symptoms.

---

## Structural Root Causes

### 1. Regulation by Scandal

The American research ethics framework has developed almost entirely in reaction to publicized abuses rather than through proactive risk assessment. This pattern produces a distinctive set of problems:

- **Overfit to past harms**: Regulations are designed to prevent the specific type of abuse that prompted them, leaving gaps for novel forms of harm. The Common Rule is well-suited to preventing another Tuskegee but poorly adapted to address AI-driven research or big data analytics
- **Cyclical neglect**: Between scandals, political will for reform dissipates. The 2018 Common Rule revision took eight years from proposal to implementation, during which the research landscape changed dramatically
- **Lag time**: The gap between the emergence of new research methodologies and the development of appropriate ethical oversight can span decades. Social media experiments, large language model training, and synthetic biology all preceded any meaningful ethical governance

### 2. Fragmented Regulatory Architecture

Research ethics oversight is distributed across multiple agencies, regulations, and institutional structures with imperfect coordination:

| Regulator | Jurisdiction | Limitations |
|-----------|-------------|-------------|
| OHRP (HHS) | Common Rule compliance for federally funded research | No authority over privately funded research |
| FDA | Clinical trials for drugs, biologics, devices | Not harmonized with Common Rule; limited scope outside product development |
| USDA-APHIS | Animal Welfare Act enforcement | Excludes rats, mice, birds; under-resourced |
| OLAW (NIH) | PHS Policy for animal care at funded institutions | Relies on institutional self-reporting |
| OSTP | DURC and biosecurity policy | Advisory; limited enforcement authority |
| NSABB | Dual-use research advisory | Advisory only; no binding authority |
| Individual institutions | All research conducted under their auspices | Massive variation in capacity, rigor, and culture |

**Consequences of fragmentation:**

- Researchers at the same institution may face different ethical requirements depending on funding source
- Multi-agency funded research may trigger overlapping and sometimes contradictory requirements
- No single entity has comprehensive oversight of all research involving human subjects, animals, or hazardous materials
- Private sector research may fall entirely outside regulatory reach

### 3. Institutional Conflict of Interest

The organizations responsible for ethical oversight are the same organizations that benefit from the research they oversee:

- **University IRBs review their own faculty's research**: IRB members are colleagues of the researchers whose protocols they evaluate, creating social pressure against rejection
- **IACUCs are populated by institutional researchers**: Animal care committees are dominated by scientists who conduct animal research at the same institution
- **Institutional financial incentives**: Universities receive indirect cost recovery (overhead) on federal grants, creating financial incentives to approve and expedite research rather than scrutinize it
- **Commercial IRBs are paid by sponsors**: The growth of for-profit IRBs, which review approximately 70% of industry-sponsored clinical trials, introduces market incentives that may favor client satisfaction over rigorous protection
- **DURC self-assessment**: Institutions are responsible for identifying their own research as dual-use, creating incentives to classify research as below the threshold requiring additional review

### 4. The Compliance-Ethics Gap

Over decades, research ethics oversight has shifted from substantive ethical deliberation toward procedural compliance:

- **Checklist culture**: IRBs increasingly focus on whether forms are complete, consent language is legally adequate, and regulatory boxes are checked, rather than engaging deeply with ethical dimensions of research design
- **Legal defensive posture**: Institutional legal counsel has become a dominant voice in IRB processes, driving consent form length and complexity beyond what participants can meaningfully comprehend
- **Bureaucratic burden without proportional protection**: Low-risk research (surveys, educational studies, analysis of existing data) often receives disproportionate scrutiny, while genuinely risky research may receive expedited review
- **Training as inoculation**: Mandatory training modules (e.g., CITI Program) are treated as sufficient ethical preparation, though completing a self-paced online course bears little relationship to ethical reasoning capacity

### 5. The Private Sector Gap

The Common Rule and most federal oversight mechanisms apply only to federally funded research or research conducted at institutions that have voluntarily committed to compliance:

- **Technology companies**: Companies like Meta, Google, Amazon, and Microsoft conduct extensive research on human behavior, sometimes involving millions of participants, with no obligation to obtain IRB review or informed consent for non-FDA-regulated activities
- **Pharmaceutical industry (non-FDA pathways)**: While clinical trials for FDA-regulated products require ethics review, early-stage research, market research with medical implications, and post-market studies may not
- **Private laboratories**: Privately funded research facilities conducting animal research on AWA-excluded species may operate without regulatory oversight
- **International research**: U.S.-based companies and researchers conducting studies abroad may exploit regulatory gaps in host countries

---

## Systemic and Cultural Root Causes

### 6. Power Asymmetries in Research Relationships

Research ethics problems disproportionately affect those with the least power to advocate for themselves:

- **Healthy volunteer exploitation**: Phase I clinical trial participants are disproportionately low-income, uninsured, and members of minority groups who participate for financial compensation
- **Prisoner research history**: Although Subpart C restricts prisoner research, incarcerated populations remain vulnerable to inadequate medical research protections within correctional healthcare
- **Global health research disparities**: Research conducted in low- and middle-income countries by U.S.-funded investigators may offer standards of care that participants could never access outside the trial
- **Patient desperation**: Terminally ill patients may consent to highly risky experimental treatments not because of genuine autonomous choice but because of desperation, a dynamic the "right to try" movement has amplified
- **Indigenous communities**: Historical exploitation of Indigenous biological samples (e.g., the Havasupai tribe case, Arizona State University) reflects persistent failure to respect community sovereignty over research participation

### 7. Publish-or-Perish Incentives

The academic career structure creates systematic pressure to conduct research quickly, producing results amenable to publication, which can erode ethical care:

- **Speed over rigor**: Competitive pressure to publish first creates incentives to minimize time spent on ethical review, informed consent processes, and community engagement
- **Negative result suppression**: The bias against publishing negative results incentivizes researchers to design studies that are more likely to produce publishable positive results, potentially compromising the genuine equipoise required for ethical clinical trials
- **Career consequences of ethical objections**: Junior researchers who raise ethical concerns about senior colleagues' protocols risk career retaliation in the absence of robust whistleblower protections
- **Grant cycle pressure**: The competitive grant system rewards researchers who demonstrate rapid productivity, which can conflict with the deliberative pace required for ethically complex research

### 8. Disciplinary Silos in Ethics Oversight

Research ethics expertise is fragmented across disciplines that rarely communicate effectively:

- **Biomedical dominance**: The Common Rule and IRB system were designed by and for biomedical researchers. Social science, computer science, and engineering research are forced into frameworks that do not fit their methodologies
- **Bioethics-biosecurity disconnect**: The communities that study human subjects protections and the communities that study biosecurity risks operate largely independently, despite significant overlap in dual-use research concerns
- **Technology gap**: IRB members, typically drawn from biomedical and behavioral science backgrounds, often lack the technical expertise to evaluate AI, machine learning, or computational research protocols
- **International ethics variation**: Different ethical traditions (principalism in the U.S., human rights frameworks in Europe, communitarian approaches in parts of Asia and Africa) complicate global research governance

### 9. Inadequate Enforcement

Even where regulations exist, enforcement is weak:

- **OHRP resource limitations**: The Office for Human Research Protections operates with approximately 40 staff members overseeing compliance at thousands of institutions
- **USDA inspection gaps**: APHIS has fewer than 120 inspectors for approximately 1,300 registered research facilities, plus thousands of other regulated entities
- **Penalties are rarely punitive**: The most common OHRP enforcement action is a "determination letter" requiring corrective action. Suspension of an institution's Federal Wide Assurance (effectively halting all federally funded research) is extremely rare
- **Whistleblower exposure**: Researchers who report ethical violations face potential retaliation, and existing whistleblower protections are not specific to research ethics concerns
- **Self-reporting dependence**: Much of the compliance system relies on institutions self-reporting violations--a structure that incentivizes concealment rather than transparency

### 10. The Consent Fiction

Informed consent, the cornerstone of human subjects protections, is increasingly inadequate as practiced:

- **Comprehension gaps**: Studies consistently show that research participants do not understand key elements of consent forms, including risks, the distinction between research and treatment (therapeutic misconception), and the right to withdraw
- **Length and complexity**: Despite 2018 reforms, consent forms remain lengthy legal documents designed to protect institutions rather than inform participants
- **Digital consent**: Click-through consent for online research, app-based studies, and data collection provides even less meaningful agreement than paper consent forms
- **Ongoing consent**: The one-time consent model is poorly adapted to longitudinal research, biobanking, or studies where research questions evolve over time
- **Broad consent**: The revised Common Rule permits "broad consent" for future unspecified research uses of stored biospecimens and data, raising questions about whether meaningful consent is possible when specific uses are unknown

---

## Root Cause Interaction Map

The root causes identified above do not operate in isolation. They reinforce each other in patterns that make reform difficult:

- **Fragmented regulation + private sector gap** = Large-scale tech company research on human behavior occurs entirely outside the regulatory framework
- **Institutional conflict of interest + compliance-ethics gap** = IRBs focus on protecting the institution from liability rather than protecting participants from harm
- **Publish-or-perish + power asymmetries** = Vulnerable populations bear disproportionate research risk while researchers capture career benefits
- **Regulation by scandal + disciplinary silos** = New forms of research (AI, synthetic biology) proceed without oversight until a scandal forces reactive regulation
- **Inadequate enforcement + self-reporting** = Institutions that violate regulations have little incentive to report violations and face minimal consequences if caught

---

## Why Previous Reforms Have Been Insufficient

| Reform | What It Addressed | What It Did Not Address |
|--------|-------------------|------------------------|
| National Research Act (1974) | Created IRBs, mandated review | Did not cover privately funded research or animal research |
| Common Rule (1991) | Standardized federal requirements | Did not apply to private sector; enforcement remained weak |
| IACUC mandate (1985) | Required institutional animal oversight | Did not close rat/mouse/bird exclusion |
| GOF moratorium (2014) | Paused funding for specific dangerous research | Was temporary; replacement framework (P3CO) lacks transparency |
| Common Rule revision (2019) | Updated consent, exemptions, single IRB | Did not extend to private sector; no AI/big data provisions |
| DURC policy update (2024) | Broadened institutional review scope | Still relies on institutional self-identification; advisory only |

## Document Navigation

- Previous: [History](03-history.md)
- Next: [Stakeholders](05-stakeholders.md)
- Up: [Science](../01-overview.md)
