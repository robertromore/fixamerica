# Artificial Intelligence: Current State

## Overview

The AI landscape in 2024-2025 is characterized by rapid technological advancement, massive investment, governance lag, and growing public concern. Large language models and generative AI have captured public attention while raising fundamental questions about employment, truth, safety, and control. The US leads in AI research and commercialization but lacks comprehensive governance frameworks.

## Technological Landscape

### Foundation Models

| Model Family | Developer | Capabilities | Access |
|--------------|-----------|--------------|--------|
| GPT-4/GPT-4o | OpenAI | Text, code, vision, reasoning | API, ChatGPT |
| Claude 3 | Anthropic | Text, code, vision, long context | API, Claude.ai |
| Gemini | Google DeepMind | Text, code, vision, multimodal | API, products |
| Llama 3 | Meta | Text, code (open weights) | Open download |
| Mistral | Mistral AI | Text, code (open weights) | Open/API |
| Command R | Cohere | Text, enterprise focus | API |

### Capability Trends

**Current capabilities:**

- Human-level performance on many benchmarks
- Code generation and debugging
- Complex reasoning and analysis
- Image, audio, video generation
- Multi-step task completion
- Real-time conversation

**Emerging capabilities:**

- Autonomous agent behavior
- Tool use and API integration
- Long-horizon planning
- Scientific research assistance
- Multimodal understanding

### Compute and Infrastructure

| Metric | Value | Trend |
|--------|-------|-------|
| Leading training runs | 10^25+ FLOPs | Doubling every 6-9 months |
| H100 GPU cost | $25,000-40,000 | Supply-constrained |
| Training cost (frontier) | $50-100+ million | Rising rapidly |
| Data center power | Gigawatts needed | Straining grids |
| Cloud AI revenue | $50+ billion/year | Growing 30%+ annually |

## Market Structure

### Industry Concentration

**Foundation model leaders:**

- OpenAI - Backed by Microsoft ($13B+)
- Anthropic - Backed by Google, Amazon ($7B+)
- Google DeepMind - Internal Google
- Meta AI - Internal Meta (open weights strategy)

**Compute providers:**

- NVIDIA - 80%+ of AI chips
- Cloud: AWS, Azure, Google Cloud
- Emerging: AMD, Intel, custom chips

**Market dynamics:**

- High barriers to entry (compute, data, talent)
- Vertical integration (cloud + models)
- Open vs. closed tension
- Startup consolidation accelerating

### Investment Levels

| Category | Annual Investment | Source |
|----------|-------------------|--------|
| VC into AI startups | $50+ billion (2023) | Pitchbook |
| Big Tech AI capex | $100+ billion | Company reports |
| Federal AI R&D | ~$3 billion | NITRD |
| AI acquisitions | $20+ billion | Dealogic |

## Current Governance

### Federal Level

**Executive Order 14110 (October 2023):**

- Requires safety testing for powerful models
- Reporting requirements for large training runs
- Directs agencies to address AI risks
- Focuses on dual-use foundation models
- Limited enforcement mechanisms

**Agency actions:**

- NIST AI Risk Management Framework (voluntary)
- FTC enforcement on deceptive AI practices
- EEOC guidance on AI in employment
- Copyright Office studying AI and IP
- OMB guidance on federal AI use

**Congressional activity:**

- Multiple bills introduced, none enacted
- Senate AI Insight Forums (2023)
- Bipartisan interest, no consensus
- Appropriations include AI research funding

### State Level

| State | Action | Status |
|-------|--------|--------|
| Colorado | AI algorithmic discrimination law | Enacted 2024 |
| California | AI safety legislation (SB 1047) | Vetoed 2024 |
| California | AI transparency, watermarking bills | Enacted 2024 |
| Texas | AI advisory council | Enacted 2023 |
| Connecticut | AI inventory, impact assessment | Enacted 2023 |

### International

**EU AI Act (2024):**

- Risk-based classification system
- Prohibited uses (social scoring, certain biometrics)
- High-risk system requirements
- Foundation model obligations
- Extraterritorial application

**Other jurisdictions:**

- UK: Pro-innovation, sector-specific approach
- China: Generative AI regulations, algorithm registry
- G7: Hiroshima AI Process principles
- UN: Advisory body on AI established

## Deployment Patterns

### Enterprise Adoption

| Sector | AI Applications | Adoption Rate |
|--------|-----------------|---------------|
| Finance | Fraud detection, trading, customer service | High |
| Healthcare | Diagnostics, drug discovery, admin | Medium-growing |
| Legal | Document review, research, drafting | Medium |
| Education | Tutoring, assessment, content | Early |
| Manufacturing | Quality control, optimization | Medium |
| Retail | Recommendations, inventory, service | High |

### Consumer Applications

**Widespread use:**

- Chatbots (ChatGPT, Claude, Gemini)
- Image generation (Midjourney, DALL-E, Stable Diffusion)
- Writing assistance (Grammarly AI, etc.)
- Search enhancement
- Voice assistants (improved)

**Emerging use:**

- AI companions and relationships
- Personal tutoring
- Health advice (concerning)
- Financial advice
- Content creation

### High-Stakes Deployments

| Domain | Applications | Concerns |
|--------|--------------|----------|
| Criminal justice | Risk assessment, facial recognition | Bias, due process |
| Employment | Resume screening, monitoring | Discrimination |
| Healthcare | Diagnosis, treatment recommendations | Accuracy, liability |
| Finance | Credit decisions, fraud detection | Fair lending |
| Government benefits | Eligibility determination | Access, accuracy |

## Safety and Risk Landscape

### Near-Term Risks

**Documented harms:**

- Discriminatory outcomes in hiring, lending, criminal justice
- Misinformation and deepfakes
- Privacy violations through data collection
- Job displacement without transition support
- Over-reliance and automation complacency
- Mental health impacts (AI companions, manipulation)

**Emerging concerns:**

- Autonomous agents with real-world actions
- Biological and chemical weapon assistance
- Cyber attack capabilities
- Manipulation at scale
- Concentration of power

### Long-Term Risks

| Risk Category | Description | Timeline |
|---------------|-------------|----------|
| Alignment | AI systems pursuing unintended goals | Uncertain |
| Control | Inability to correct or shut down systems | Uncertain |
| Power concentration | AI advantages locked in by few actors | Ongoing |
| Weaponization | Autonomous weapons, AI arms race | Ongoing |
| Existential | Risks to human existence or flourishing | Debated |

### Safety Research

**Key organizations:**

- Anthropic (Constitutional AI, interpretability)
- OpenAI Safety team
- Google DeepMind Safety
- MIRI, Redwood Research, ARC
- Academic labs (Berkeley, MIT, etc.)

**Research areas:**

- Interpretability and transparency
- Alignment and value learning
- Robustness and reliability
- Evaluation and benchmarking
- Governance and policy

## Workforce Impacts

### Current Effects

| Impact | Evidence | Scale |
|--------|----------|-------|
| Task automation | Writing, coding, analysis assistance | Widespread |
| Productivity gains | 20-80% on specific tasks | Documented |
| Job displacement | Limited direct displacement so far | Growing |
| New job creation | AI trainers, prompt engineers, etc. | Modest |
| Wage pressure | Effects beginning in some sectors | Early |

### Projections

**Optimistic view:**

- Augmentation more than replacement
- New jobs created
- Productivity gains broadly shared
- Gradual transition

**Pessimistic view:**

- Rapid displacement
- Concentration of gains
- Skills mismatch
- Inadequate safety net

### Affected Occupations

| Category | Risk Level | Examples |
|----------|------------|----------|
| Routine cognitive | High | Data entry, basic analysis |
| Creative | Medium-High | Writing, design, music |
| Professional | Medium | Law, medicine, finance |
| Technical | Medium | Programming, engineering |
| Physical service | Lower | Healthcare, construction |
| Physical labor | Variable | Depends on robotics |

## Public Opinion

### Awareness and Attitudes

| Metric | Finding | Source |
|--------|---------|--------|
| AI awareness | 90%+ have heard of AI | Pew 2023 |
| ChatGPT awareness | 60%+ have heard of it | Pew 2023 |
| Concern about AI | 52% more concerned than excited | Pew 2023 |
| Regulation support | 70%+ favor some regulation | Morning Consult |
| Trust in AI companies | Low (30-40%) | Edelman |
| Job loss concern | 60%+ worried about impacts | Various |

### Partisan Differences

- Concern about AI crosses party lines
- Regulation approaches differ
- National security concerns bipartisan
- Economic impacts concern both parties
- Different emphases on innovation vs. safety

## Key Gaps and Challenges

### Governance Gaps

1. **No comprehensive federal law** - Patchwork of agency actions
2. **Liability uncertainty** - Who is responsible for AI harms?
3. **Enforcement capacity** - Agencies lack AI expertise
4. **Speed mismatch** - Technology outpaces regulation
5. **International coordination** - Limited global governance

### Technical Challenges

1. **Interpretability** - Cannot fully explain model behavior
2. **Evaluation** - Hard to measure safety and alignment
3. **Robustness** - Systems fail in unexpected ways
4. **Data quality** - Training data biases and errors
5. **Security** - Jailbreaks, adversarial attacks

### Societal Challenges

1. **Inequality** - Benefits concentrated, costs diffuse
2. **Workforce transition** - No adequate preparation
3. **Democratic discourse** - Synthetic media threats
4. **Power concentration** - Few companies control AI
5. **Global competition** - Pressure against safety measures

## Trajectory

### Near-Term (1-2 years)

- Continued capability improvements
- Broader enterprise deployment
- More state-level legislation
- Possible federal action
- EU AI Act implementation begins
- Agent systems emerge

### Medium-Term (3-5 years)

- Significant economic restructuring
- Clearer governance frameworks
- Major incidents likely
- International frameworks develop
- Open vs. closed resolved
- Automation impacts visible

### Long-Term (5+ years)

- Transformative economic changes
- Potential for advanced AI systems
- Governance either succeeds or fails
- Power structures reshaped
- Unknown capabilities emerge

---

## Document Navigation

- Previous: [Overview](01-overview.md)
- Next: [History](03-history.md)
- Up: [Overview](01-overview.md)
