# Artificial Intelligence: History

## Overview

The history of artificial intelligence spans seven decades of research, periodic hype cycles, and recent explosive growth. Understanding this history illuminates why current governance is inadequate, how the field developed its culture and assumptions, and what lessons past AI winters and breakthroughs offer for policy.

## Timeline of Key Developments

### 1950s-1960s: Birth of the Field

| Year | Development | Significance |
|------|-------------|--------------|
| 1950 | Turing publishes "Computing Machinery and Intelligence" | Proposes Turing test |
| 1956 | Dartmouth Conference | "Artificial Intelligence" coined |
| 1958 | Perceptron invented (Rosenblatt) | First neural network |
| 1966 | ELIZA chatbot (Weizenbaum) | Early natural language |
| 1969 | SHAKEY robot (SRI) | Integrated AI system |

**Early optimism:**
- Predictions of human-level AI within 20 years
- Substantial government funding (DARPA)
- Focus on symbolic reasoning, logic
- General problem solver approaches

### 1970s-1980s: First AI Winter and Expert Systems

| Year | Development | Significance |
|------|-------------|--------------|
| 1969 | Minsky & Papert critique perceptrons | Neural network funding collapses |
| 1973 | Lighthill Report (UK) | Government funding cut |
| 1974-1980 | First AI Winter | Reduced funding, pessimism |
| 1980s | Expert systems boom | Rule-based commercial AI |
| 1987 | Expert systems bust | Overpromise, underdeliver |

**Lessons:**
- Overhyped predictions lead to backlash
- Narrow AI successes, general AI failures
- Commercial pressures distort research

### 1990s-2000s: Machine Learning Rise

| Year | Development | Significance |
|------|-------------|--------------|
| 1997 | Deep Blue beats Kasparov | Chess milestone |
| 1998 | Google founded | Search uses ML techniques |
| 2006 | Hinton deep learning breakthrough | Neural networks revived |
| 2007 | iPhone launched | Mobile data explosion |

**Shift to data-driven approaches:**
- Statistical methods over symbolic
- Internet provides training data
- Computing power increases
- Academic progress accumulates

### 2010s: Deep Learning Revolution

| Year | Development | Significance |
|------|-------------|--------------|
| 2011 | IBM Watson wins Jeopardy! | NLP milestone |
| 2012 | AlexNet wins ImageNet | Deep learning breakthrough |
| 2014 | Google acquires DeepMind ($500M) | Big tech AI race begins |
| 2015 | OpenAI founded | Non-profit AI lab |
| 2016 | AlphaGo beats Lee Sedol | Game AI milestone |
| 2017 | Transformer architecture (Google) | Foundation for LLMs |
| 2018 | BERT language model | NLP advances |
| 2018 | GPT-1 released | Generative pre-training |

**Key dynamics:**
- GPU computing enables deep learning
- Big tech dominates research
- Academic-industry talent flow
- Open research culture (papers, code)

### 2020s: Foundation Models and Generative AI

| Year | Development | Significance |
|------|-------------|--------------|
| 2020 | GPT-3 released | Scale unlocks capabilities |
| 2021 | DALL-E (image generation) | Multimodal AI |
| 2021 | GitHub Copilot | AI coding assistance |
| 2022 | ChatGPT launched (Nov 30) | AI enters mainstream |
| 2022 | Stable Diffusion released | Open image generation |
| 2023 | GPT-4 released | Multimodal, reasoning |
| 2023 | Claude 2 released | Constitutional AI |
| 2023 | Executive Order 14110 | First major US AI policy |
| 2024 | EU AI Act finalized | Comprehensive AI law |
| 2024 | Claude 3, GPT-4o, Gemini | Capability advances |

## History of AI Governance

### Early Period (1950s-1990s)

- **Minimal governance**: Academic freedom
- **Defense funding**: DARPA shaped research priorities
- **No regulatory framework**: Self-governance
- **Export controls**: Cold War tech restrictions

### Early Commercial Era (1990s-2010s)

| Development | Governance Response |
|-------------|---------------------|
| Internet AI (search, ads) | Section 230, general tech law |
| Financial AI | Existing financial regulation |
| Industrial AI | Product safety laws |

**Pattern**: Apply existing laws, no AI-specific rules

### Big Data Era (2010s)

| Issue | Response |
|-------|----------|
| Algorithmic discrimination | FTC, EEOC guidance |
| Facial recognition | Local bans emerge |
| Autonomous vehicles | State-level frameworks |
| Social media algorithms | Hearings, no legislation |

**Challenges:**
- Algorithms opaque
- Harms difficult to prove
- Industry opposed regulation
- Rapid deployment outpaced policy

### Generative AI Era (2020s)

**Federal response:**
- 2022: AI Bill of Rights (non-binding)
- 2023: Executive Order 14110
- 2023: NIST AI Risk Management Framework
- 2024: Multiple bills introduced, none passed
- 2024: Agency guidance proliferates

**State response:**
- Colorado AI Act (algorithmic discrimination)
- California attempts (SB 1047 vetoed)
- Various transparency requirements

**International:**
- EU AI Act (comprehensive)
- UK pro-innovation approach
- China generative AI regulations
- UN advisory body

## History of AI Research Culture

### Academic Origins

- Open publication norm
- Peer review process
- International collaboration
- Curiosity-driven research
- Focus on capability, less on safety

### Industry Transformation

| Era | Research Model |
|-----|----------------|
| 1990s | Academic labs dominant |
| 2000s | Industry labs emerge (Google, Microsoft) |
| 2010s | Industry surpasses academia |
| 2020s | Frontier research requires industry scale |

**Consequences:**
- Profit motives shape research
- Talent concentrated in industry
- Less public research
- Speed prioritized

### Safety Research History

| Year | Development |
|------|-------------|
| 1960s | Early warnings (Wiener) |
| 2000s | Bostrom, Yudkowsky on risks |
| 2014 | Open letter on AI safety |
| 2015 | OpenAI founded (safety focus) |
| 2015 | DeepMind ethics board |
| 2017 | Asilomar AI Principles |
| 2021 | Anthropic founded (safety focus) |
| 2023 | Safety research mainstreamed |

### Open vs. Closed Debate

**Open research tradition:**
- Share papers, code, models
- Scientific reproducibility
- Democratize access
- Enable scrutiny

**Closed model arguments:**
- Prevent misuse
- Commercial advantage
- Safety through restriction
- Controlled deployment

**Current state:**
- Frontier models largely closed
- Open alternatives (Llama, Mistral)
- Ongoing tension

## Historical Lessons

### From AI Winters

1. **Overpromise leads to backlash** - Realistic expectations matter
2. **Narrow success, general failure** - Broad claims often wrong
3. **Funding volatility hurts research** - Stable support needed
4. **Commercial pressure distorts** - Incentives shape development

### From Tech Governance

1. **Reactive regulation** - Policy follows harm
2. **Capture risks** - Industry shapes rules
3. **Pace mismatch** - Technology moves faster than policy
4. **Global challenges** - Unilateral action limited

### From Other Technologies

| Technology | Lesson |
|------------|--------|
| Nuclear | International cooperation possible but fragile |
| Biotech | Voluntary moratorium can work temporarily |
| Internet | Early design choices have lasting effects |
| Social media | Rapid scale creates unforeseen harms |
| Finance | Complexity enables regulatory arbitrage |

## Evolution of Key Concepts

### "Artificial Intelligence" Meaning

| Era | Dominant Meaning |
|-----|------------------|
| 1950s-60s | Human-level reasoning |
| 1970s-80s | Expert systems |
| 1990s-2000s | Machine learning |
| 2010s | Deep learning |
| 2020s | Large language models, generative AI |

### "AI Safety" Evolution

| Period | Focus |
|--------|-------|
| Early | Reliability, bugs |
| 2000s | Long-term existential risk |
| 2010s | Bias, fairness, accountability |
| 2020s | Alignment, misuse, capability risks |

### Governance Paradigms

| Era | Paradigm |
|-----|----------|
| 1950s-1990s | Self-governance |
| 1990s-2010s | Apply existing law |
| 2010s | Principles and ethics |
| 2020s | Emerging regulation |

## Historical Actors

### Key Researchers

| Person | Contribution |
|--------|--------------|
| Alan Turing | Foundational theory |
| John McCarthy | Coined "AI," Lisp |
| Marvin Minsky | Neural networks, MIT AI Lab |
| Geoffrey Hinton | Deep learning pioneer |
| Yann LeCun | Convolutional networks |
| Yoshua Bengio | Deep learning pioneer |
| Fei-Fei Li | ImageNet, vision |
| Dario Amodei | Anthropic, safety |
| Sam Altman | OpenAI |
| Demis Hassabis | DeepMind |

### Key Institutions

| Institution | Role |
|-------------|------|
| DARPA | Early funding |
| MIT AI Lab | Academic research |
| Stanford AI Lab | Academic research |
| Google/DeepMind | Commercial research |
| OpenAI | Mixed model |
| Anthropic | Safety-focused |

### Government Actors

| Entity | Role |
|--------|------|
| DARPA | Research funding |
| NSF | Academic support |
| NIST | Standards development |
| FTC | Consumer protection |
| White House OSTP | Policy coordination |

## What History Suggests About the Future

### Patterns Likely to Continue

- Capability advances continuing
- Concentration of resources
- Governance lag
- Hype and backlash cycles
- International competition

### Key Uncertainties

- Timing of transformative AI
- Whether safety research succeeds
- Governance effectiveness
- Open vs. closed resolution
- Economic impacts timeline

### Historical Analogies

| Analogy | Suggests |
|---------|----------|
| Industrial Revolution | Massive disruption, eventual adaptation |
| Nuclear weapons | Arms race, eventual governance |
| Internet | Rapid deployment, delayed governance |
| Biotech | Mixed success with governance |

---

## Document Navigation

- Previous: [Current State](02-current-state.md)
- Next: [Root Causes](04-root-causes.md)
- Up: [Overview](01-overview.md)
