# Technology Policy: Legislation and Legal Framework

## Overview

Technology policy legislation spans privacy, competition, AI governance, platform accountability, and cybersecurity. The absence of comprehensive federal frameworks has led to state-level action and reliance on existing authorities. This document outlines key legislative reforms needed to address technology governance gaps.

## Constitutional Amendments

### Digital Rights Amendment

**Purpose**: Establish constitutional foundation for privacy and digital rights.

**Draft Text**:

```text
Section 1. The right of the people to be secure in their personal
data, digital communications, and online activities against
unreasonable collection, use, and disclosure, shall not be violated.

Section 2. No person shall be subject to discrimination by automated
decision systems without meaningful opportunity for human review.

Section 3. Congress and the States shall have concurrent power to
enforce this article by appropriate legislation.

Section 4. This article shall take effect two years after ratification.
```

**Explanation**:

- Section 1 extends Fourth Amendment principles to digital realm
- Section 2 establishes due process for algorithmic decisions
- Section 3 enables both federal and state action
- Addresses evolving technology landscape

**Potential Challenges**:

- Constitutional amendment process is difficult
- Business opposition to data limitations
- Enforcement complexity
- Technology evolution may outpace text

**Refinements**:

- Pursue statutory solutions first
- Build state constitutional precedents
- Use as aspirational framework

## Federal Legislation

### American Privacy Rights Act

**Purpose**: Establish comprehensive federal privacy law with meaningful consumer rights and enforcement.

**Draft Text**:

```text
SEC. 1. SHORT TITLE.

This Act may be cited as the "American Privacy Rights Act".

SEC. 2. DEFINITIONS.

(a) Personal Data.—The term "personal data" means information that
identifies or is reasonably linkable to an individual.

(b) Sensitive Data.—The term "sensitive data" includes—
  (1) social security numbers;
  (2) financial account information;
  (3) precise geolocation;
  (4) biometric information;
  (5) health information;
  (6) communications content;
  (7) data concerning minors;
  (8) sexual orientation or gender identity information;
  (9) immigration status.

(c) Covered Entity.—The term "covered entity" means any entity
that collects, processes, or transfers personal data, excluding—
  (1) entities with annual revenue under $25,000,000;
  (2) entities processing data of fewer than 50,000 individuals;
  (3) government entities.

SEC. 3. DATA MINIMIZATION.

(a) Limitation.—A covered entity may not collect, process, or
transfer personal data except as reasonably necessary to—
  (1) provide a product or service requested by the individual;
  (2) communicate with the individual;
  (3) maintain security;
  (4) comply with legal obligations.

(b) Sensitive Data.—A covered entity may not collect, process, or
transfer sensitive data without express opt-in consent.

SEC. 4. CONSUMER RIGHTS.

(a) Access.—Individuals have the right to access personal data
held about them.

(b) Correction.—Individuals have the right to correct inaccurate
personal data.

(c) Deletion.—Individuals have the right to delete personal data,
subject to legal retention requirements.

(d) Portability.—Individuals have the right to obtain their data
in a portable format.

(e) Opt-Out.—Individuals have the right to opt out of—
  (1) targeted advertising;
  (2) data transfers to third parties;
  (3) profiling for significant decisions.

SEC. 5. ALGORITHMIC ACCOUNTABILITY.

(a) Impact Assessment.—Covered entities using algorithms for
significant decisions shall conduct impact assessments.

(b) Disclosure.—Individuals shall be notified when significant
decisions are made using algorithms.

(c) Human Review.—Individuals have the right to human review
of algorithmic decisions that significantly affect them.

SEC. 6. ENFORCEMENT.

(a) FTC Authority.—The Federal Trade Commission shall enforce
this Act and may promulgate regulations.

(b) State Attorneys General.—State attorneys general may bring
civil actions to enforce this Act.

(c) Private Right of Action.—
  (1) Any individual harmed by a violation may bring civil action.
  (2) Prevailing plaintiffs may recover actual damages, statutory
  damages of up to $5,000 per violation, and attorney fees.

(d) Civil Penalties.—Civil penalties shall be the greater of—
  (1) 4 percent of global annual revenue; or
  (2) $50,000 per violation.

SEC. 7. PREEMPTION.

(a) Floor Not Ceiling.—This Act establishes minimum protections.
States may enact stronger protections.

(b) Federal Preemption.—State laws providing lesser protections
are preempted.
```

**Explanation**:

- Comprehensive rights similar to GDPR
- Data minimization limits collection
- Meaningful enforcement with private right of action
- States can go further (floor, not ceiling)

**Potential Challenges**:

- Industry opposition to private right of action
- Preemption debates
- Small business compliance concerns
- Enforcement resource constraints

**Refinements**:

- Phase in requirements by entity size
- Create safe harbors for compliant entities
- Provide technical assistance for small businesses

### Platform Accountability and Competition Act

**Purpose**: Address platform dominance through interoperability, non-discrimination, and structural remedies.

**Draft Text**:

```text
SEC. 1. SHORT TITLE.

This Act may be cited as the "Platform Accountability and
Competition Act".

SEC. 2. DEFINITIONS.

(a) Covered Platform.—A platform is a "covered platform" if it—
  (1) has at least 50 million monthly active users in the United
  States or 100,000 monthly active business users;
  (2) has annual revenue or market capitalization exceeding
  $600 billion; and
  (3) is a critical trading partner for a significant number
  of business users.

SEC. 3. NON-DISCRIMINATION.

(a) Prohibition.—A covered platform may not—
  (1) preference its own products over those of competitors;
  (2) use non-public data from business users to compete
  against them;
  (3) condition access on exclusive dealing arrangements;
  (4) retaliate against users for raising concerns publicly.

SEC. 4. INTEROPERABILITY.

(a) Data Portability.—Users shall be able to transfer their data
to competing services.

(b) API Access.—Covered platforms shall provide reasonable API
access to third parties on fair terms.

(c) Messaging Interoperability.—Messaging platforms with over
100 million users shall enable interoperability with other
messaging services.

SEC. 5. MERGER RESTRICTIONS.

(a) Presumption.—Acquisitions by covered platforms of companies
valued at $50 million or more are presumptively anticompetitive.

(b) Rebuttal.—The presumption may be rebutted by clear and
convincing evidence that the acquisition—
  (1) will not reduce competition; and
  (2) will provide clear consumer benefits unavailable
  through internal development.

SEC. 6. LINE OF BUSINESS RESTRICTIONS.

(a) Structural Separation.—Upon finding of violation, the
Commission may require covered platforms to—
  (1) divest business lines;
  (2) maintain functional separation between business units;
  (3) cease operation in specified markets.

SEC. 7. ENFORCEMENT.

(a) FTC Authority.—The Federal Trade Commission shall enforce
this Act.

(b) State Attorneys General.—State attorneys general may enforce
this Act.

(c) Private Enforcement.—Business users may bring actions for
violations affecting them.
```

**Explanation**:

- Targets only the largest platforms
- Non-discrimination prevents self-preferencing
- Interoperability reduces lock-in
- Structural remedies available for violations

**Potential Challenges**:

- Constitutional challenges to structural remedies
- Defining covered platforms
- International coordination
- Implementation complexity

**Refinements**:

- Regular threshold updates
- Safe harbors for compliant platforms
- Coordination with DOJ enforcement

### AI Safety and Accountability Act

**Purpose**: Establish risk-based framework for AI governance with safety requirements and liability.

**Draft Text**:

```text
SEC. 1. SHORT TITLE.

This Act may be cited as the "AI Safety and Accountability Act".

SEC. 2. DEFINITIONS.

(a) Artificial Intelligence System.—A machine-based system that
makes predictions, recommendations, or decisions influencing
real or virtual environments.

(b) High-Risk AI System.—An AI system used in—
  (1) employment decisions;
  (2) credit determinations;
  (3) housing decisions;
  (4) criminal justice;
  (5) healthcare diagnosis or treatment;
  (6) education admissions or assessments;
  (7) critical infrastructure control;
  (8) biometric identification.

(c) Frontier AI Model.—An AI model trained using computing
resources exceeding thresholds set by the Secretary.

SEC. 3. HIGH-RISK AI REQUIREMENTS.

(a) Pre-Deployment Assessment.—Deployers of high-risk AI shall—
  (1) conduct impact assessments for bias, accuracy, and safety;
  (2) document training data, methodology, and limitations;
  (3) test for disparate impact on protected classes.

(b) Ongoing Monitoring.—Deployers shall monitor deployed systems
and address identified issues.

(c) Human Oversight.—High-risk decisions shall include meaningful
human review opportunity.

(d) Notice.—Individuals shall be informed when AI is used in
decisions significantly affecting them.

SEC. 4. FRONTIER MODEL REQUIREMENTS.

(a) Safety Evaluation.—Developers of frontier AI models shall
conduct safety evaluations before deployment.

(b) Red-Teaming.—Frontier models shall undergo adversarial testing.

(c) Incident Reporting.—Safety incidents shall be reported to
the Department within 72 hours.

(d) Computing Thresholds.—The Secretary shall set computing
thresholds defining frontier models, to be updated annually.

SEC. 5. PROHIBITED PRACTICES.

The following AI applications are prohibited—
  (1) social scoring systems;
  (2) subliminal manipulation;
  (3) exploitation of vulnerabilities;
  (4) real-time biometric identification in public spaces,
  except for specified law enforcement purposes with
  judicial authorization.

SEC. 6. LIABILITY.

(a) Defective AI.—Developers are strictly liable for harm caused
by defective AI systems.

(b) Deployment Liability.—Deployers are liable for harm from
failure to comply with this Act.

(c) Safe Harbor.—Compliance with this Act creates rebuttable
presumption of reasonable care.

SEC. 7. ENFORCEMENT.

(a) Federal Enforcement.—The Federal Trade Commission shall
enforce this Act.

(b) State Enforcement.—State attorneys general may enforce.

(c) Private Action.—Individuals harmed by violations may sue
for damages.
```

**Explanation**:

- Risk-based approach focuses regulation on harmful uses
- Pre-deployment requirements catch problems early
- Frontier model provisions address cutting-edge risks
- Liability framework creates accountability

**Potential Challenges**:

- Defining "artificial intelligence" precisely
- Keeping pace with technology change
- International competitiveness concerns
- Enforcement capacity

**Refinements**:

- Regular threshold updates
- Sandbox for experimental uses
- International standards alignment

## State Model Legislation

### State Consumer Data Privacy Act

**Purpose**: Establish comprehensive state privacy law where federal action is absent.

**Draft Text**:

```text
SECTION 1. SHORT TITLE.

This Act may be cited as the "[State] Consumer Data Privacy Act".

SECTION 2. CONSUMER RIGHTS.

Consumers have the right to—
  (a) Access personal data held about them;
  (b) Correct inaccurate personal data;
  (c) Delete personal data;
  (d) Obtain data in portable format;
  (e) Opt out of sale of personal data;
  (f) Opt out of targeted advertising;
  (g) Not be discriminated against for exercising rights.

SECTION 3. BUSINESS OBLIGATIONS.

Businesses shall—
  (a) Provide clear privacy notices;
  (b) Limit collection to disclosed purposes;
  (c) Implement reasonable security;
  (d) Conduct assessments for high-risk processing;
  (e) Honor consumer requests within 45 days.

SECTION 4. ENFORCEMENT.

  (a) The Attorney General shall enforce this Act;
  (b) Civil penalties up to $7,500 per intentional violation;
  (c) [Optional: Private right of action for data breaches].
```

**Explanation**:

- Modeled on California, Virginia, Colorado approaches
- Provides consumer rights framework
- AG enforcement as baseline

**Adaptations**:

- States may add or remove private right of action
- Threshold for covered businesses varies
- Opt-in vs. opt-out approaches

### State AI Transparency Act

**Purpose**: Require transparency and accountability for AI in state government and high-risk private uses.

**Draft Text**:

```text
SECTION 1. SHORT TITLE.

This Act may be cited as the "[State] AI Transparency Act".

SECTION 2. STATE GOVERNMENT AI.

  (a) Inventory.—Each state agency shall maintain a public
  inventory of AI systems used in decision-making.

  (b) Impact Assessment.—Before deploying AI for decisions
  affecting individuals, agencies shall complete impact
  assessments.

  (c) Notice.—Individuals shall be notified when AI is used
  in decisions affecting them.

  (d) Appeal.—Individuals may request human review of AI-assisted
  government decisions.

SECTION 3. PRIVATE SECTOR HIGH-RISK AI.

  (a) Deployers of AI in employment, housing, credit, or
  insurance decisions shall—
    (1) conduct impact assessments;
    (2) test for discriminatory effects;
    (3) provide notice to affected individuals.

SECTION 4. ENFORCEMENT.

The Attorney General shall enforce this Act.
```

**Explanation**:

- Addresses government AI use specifically
- Extends to private high-risk uses
- Focuses on transparency and accountability

**Adaptations**:

- Scope of covered private uses varies
- Enforcement mechanisms vary by state

## Regulatory Framework

### FTC Privacy Rule

**Existing Authority**: Section 5 of FTC Act (unfair or deceptive practices)

**Draft Regulation**:

```text
16 CFR Part 464 - COMMERCIAL SURVEILLANCE AND DATA SECURITY

§ 464.1 Definitions.

(a) "Commercial surveillance" means collection, use, or transfer
of personal data for commercial purposes.

(b) "Substantial injury" includes financial harm, privacy harm,
reputational harm, and psychological harm.

§ 464.2 Prohibited Practices.

It is an unfair practice for a covered entity to—
  (a) Collect personal data beyond what is reasonably necessary;
  (b) Transfer sensitive data without affirmative express consent;
  (c) Use dark patterns to obtain consent;
  (d) Fail to implement reasonable data security measures;
  (e) Retain personal data longer than reasonably necessary.

§ 464.3 Required Practices.

Covered entities shall—
  (a) Provide clear, concise privacy notices;
  (b) Honor consumer opt-out requests within 15 days;
  (c) Conduct data security risk assessments annually;
  (d) Report data breaches affecting 500+ individuals.
```

**Explanation**: Exercises existing FTC authority to address commercial surveillance practices pending legislation.

### NIST AI Risk Management Framework Implementation

**Existing Authority**: NIST Organic Act, AI Executive Order

**Draft Guidance**:

```text
NIST AI RMF Implementation Guide

1. GOVERN
  - Establish AI governance structure
  - Define roles and responsibilities
  - Integrate with enterprise risk management

2. MAP
  - Identify AI systems in use
  - Categorize by risk level
  - Document intended uses and limitations

3. MEASURE
  - Evaluate for bias, accuracy, security
  - Test with diverse datasets
  - Monitor real-world performance

4. MANAGE
  - Implement risk mitigation measures
  - Establish incident response procedures
  - Plan for model updates and retirement
```

**Explanation**: Provides voluntary framework for organizations managing AI risk.

## Legal Considerations

### Constitutional Issues

| Issue | Analysis |
|-------|----------|
| **First Amendment** | Content-neutral regulations likely survive; targeting speech more difficult |
| **Commerce Clause** | Federal authority to regulate interstate data commerce well-established |
| **Due Process** | Algorithmic decision requirements serve due process values |
| **Takings** | Data limitations unlikely to be takings if applied prospectively |
| **Preemption** | Federal floor allows states to provide greater protection |

### Preemption Questions

| Area | Federal-State Balance |
|------|----------------------|
| **Privacy** | Floor preemption preserves stronger state laws |
| **AI** | Mixed federal-state approach emerging |
| **Competition** | Federal and state concurrent enforcement |
| **Cybersecurity** | Sector-specific federal rules, state breach laws |

### Enforcement Mechanisms

| Mechanism | Application |
|-----------|-------------|
| **FTC enforcement** | Section 5 authority, civil penalties |
| **DOJ antitrust** | Sherman Act, Clayton Act |
| **State AGs** | Consumer protection, privacy |
| **Private litigation** | Class actions, individual suits |
| **SEC disclosure** | Cybersecurity, AI risk disclosure |

### Sunset and Review Provisions

| Provision | Schedule |
|-----------|----------|
| **Threshold updates** | Annual review of covered entity thresholds |
| **Technology assessment** | Biennial review of AI definitions |
| **Effectiveness evaluation** | 5-year comprehensive review |
| **International alignment** | Regular harmonization assessment |

## Loopholes, Shortcomings, and Rectification

### Potential Loopholes

| Loophole | Description | Severity |
|----------|-------------|----------|
| **Small entity exemption** | Privacy law excludes small companies | Medium |
| **Research exception** | May be exploited for surveillance | Medium |
| **Consent manufacturing** | Dark patterns obtain nominal consent | High |
| **Jurisdictional arbitrage** | Companies incorporate elsewhere | Medium |
| **Definition gaming** | AI definitions may be evaded | Medium |

### Shortcomings

| Issue | Impact | Root Cause |
|-------|--------|------------|
| **Enforcement resources** | Limited FTC capacity | Underfunding |
| **Technical complexity** | Regulators lack expertise | Talent gap |
| **Speed of change** | Rules lag technology | Process constraints |
| **International coordination** | Conflicting requirements | Sovereignty |

### Rectification Procedures

1. **Threshold indexing**: Automatic adjustment of covered entity thresholds to inflation and technology change
2. **FTC funding**: Dedicated funding stream from registration fees
3. **Technical capacity**: NIST AI Safety Institute with testing capabilities
4. **Consent standards**: Specific requirements for valid consent beyond notice
5. **Definition updates**: Annual review of technology definitions

### General Implementation Concerns

- Agency capacity constraints
- Industry compliance timeline
- International harmonization
- Technology evolution
- Political sustainability

## References

### Federal Law

- Federal Trade Commission Act, 15 U.S.C. § 45
- Sherman Antitrust Act, 15 U.S.C. §§ 1-7
- Clayton Act, 15 U.S.C. §§ 12-27
- Communications Act, 47 U.S.C. § 230
- Computer Fraud and Abuse Act, 18 U.S.C. § 1030
- Children's Online Privacy Protection Act, 15 U.S.C. §§ 6501-6506

### Court Cases

- *FTC v. Facebook, Inc.*, No. 1:20-cv-03590 (D.D.C.)
- *United States v. Google LLC*, No. 1:20-cv-03010 (D.D.C.)
- *Epic Games v. Apple*, 67 F.4th 946 (9th Cir. 2023)
- *NetChoice v. Paxton*, 49 F.4th 439 (5th Cir. 2022)

### International

- General Data Protection Regulation (EU) 2016/679
- Digital Services Act (EU) 2022/2065
- Digital Markets Act (EU) 2022/1925
- EU AI Act (EU) 2024/1689

## Related Topics

- [Privacy](../privacy/01-overview.md) - Data protection detail
- [Economic Policy](../economic/01-overview.md) - Competition, antitrust
- [Political Reform](../political/01-overview.md) - Platform and democracy

---

## Document Navigation

- Previous: [Actions](10-actions.md)
- Up: [Overview](01-overview.md)
