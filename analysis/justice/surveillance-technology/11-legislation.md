# Surveillance Technology in Criminal Justice: Model Legislation

## Introduction

This document provides model legislation for regulating surveillance technology at the federal, state, and local levels. These templates are designed to be adapted to specific jurisdictions and circumstances, providing a starting point for legislative drafting.

---

## Federal Bills

### Facial Recognition and Biometric Technology Moratorium Act

```
SEC. 1. SHORT TITLE.

This Act may be cited as the "Facial Recognition and Biometric Technology
Moratorium Act."

SEC. 2. FINDINGS.

Congress finds the following:

(1) Facial recognition technology poses unique threats to civil rights and
    civil liberties, including the right to privacy and the right to free
    association.

(2) Studies have consistently demonstrated that facial recognition technology
    produces significantly higher error rates for women, the elderly, and
    people of color, particularly Black Americans.

(3) False positives in facial recognition systems have led to wrongful
    arrests, detentions, and the deprivation of constitutional rights.

(4) Facial recognition technology enables persistent surveillance that
    fundamentally alters the relationship between individuals and the
    government.

(5) The deployment of facial recognition technology by Federal, State, and
    local law enforcement agencies has proceeded without adequate public
    debate, legislative authorization, or regulatory oversight.

(6) A moratorium on the use of facial recognition technology is necessary
    to prevent ongoing harm while Congress develops appropriate safeguards.

SEC. 3. DEFINITIONS.

In this Act:

(1) BIOMETRIC SURVEILLANCE.—The term "biometric surveillance" means the use
    of biometric technology to identify or track an individual based on the
    individual's biometric information.

(2) BIOMETRIC TECHNOLOGY.—The term "biometric technology" means technology
    that uses an automated or semi-automated process to identify an individual
    or capture information about an individual based on the individual's
    biometric information.

(3) BIOMETRIC INFORMATION.—The term "biometric information" means any
    measurable physiological, biological, or behavioral characteristics that
    can be used to identify an individual, including—
    (A) facial features;
    (B) fingerprints;
    (C) voice prints;
    (D) iris or retina images;
    (E) gait or movement patterns; and
    (F) other identifying physiological characteristics.

(4) FACIAL RECOGNITION TECHNOLOGY.—The term "facial recognition technology"
    means an automated or semi-automated process that assists in identifying
    or verifying an individual or capturing information about an individual
    based on the physical characteristics of an individual's face.

(5) FEDERAL AGENCY.—The term "Federal agency" means any department, agency,
    bureau, or other governmental entity of the Federal Government.

(6) LAW ENFORCEMENT AGENCY.—The term "law enforcement agency" means any
    Federal, State, local, or Tribal agency engaged in the prevention,
    detection, or investigation of violations of criminal, immigration, or
    customs laws.

SEC. 4. MORATORIUM ON USE OF BIOMETRIC SURVEILLANCE.

(a) FEDERAL USE PROHIBITED.—No Federal agency or Federal official may—
    (1) acquire, possess, access, or use any biometric surveillance system in
        the United States;
    (2) use information derived from any biometric surveillance system operated
        by another Federal agency, State, locality, or private entity; or
    (3) contract with, or provide funding to, any third party for the purpose
        of acquiring, possessing, accessing, or using a biometric surveillance
        system on behalf of the Federal Government.

(b) STATE AND LOCAL USE.—No State or local law enforcement agency may—
    (1) acquire, possess, access, or use any biometric surveillance system; or
    (2) use information derived from any biometric surveillance system operated
        by another entity;
    if the agency receives funds under any Federal grant program administered
    by the Department of Justice or Department of Homeland Security.

(c) EXCEPTION.—The prohibitions in this section shall not apply to the use
    of biometric technology solely to—
    (1) unlock a device with the consent of the device owner; or
    (2) automatically redact biometric identifiers for privacy protection.

SEC. 5. PROHIBITION ON FEDERAL FUNDING.

(a) IN GENERAL.—No Federal funds may be used to—
    (1) acquire facial recognition technology or other biometric surveillance
        technology;
    (2) operate or maintain facial recognition or biometric surveillance systems;
    (3) enter into contracts for facial recognition or biometric surveillance
        services; or
    (4) provide grants or other funding to State or local agencies for facial
        recognition or biometric surveillance purposes.

(b) GRANT CONDITIONS.—As a condition of receiving any grant under any program
    administered by the Department of Justice or the Department of Homeland
    Security, a State or local government entity shall certify that it does
    not use facial recognition or biometric surveillance technology for law
    enforcement purposes.

SEC. 6. EVIDENTIARY PROHIBITION.

No information derived from biometric surveillance may be used as evidence
in any criminal, civil, or administrative proceeding, including for the
purpose of establishing reasonable suspicion, probable cause, or grounds
for a stop, search, arrest, or detention.

SEC. 7. PRIVATE RIGHT OF ACTION.

(a) CAUSE OF ACTION.—Any individual subjected to the use of biometric
    surveillance in violation of this Act may bring a civil action in an
    appropriate Federal district court.

(b) RELIEF.—In any action under this section, the court may award—
    (1) actual damages, but not less than liquidated damages of $25,000 per
        violation;
    (2) punitive damages;
    (3) reasonable attorney's fees and litigation costs; and
    (4) any other relief, including equitable or declaratory relief, that the
        court determines appropriate.

SEC. 8. SUNSET AND REVIEW.

(a) DURATION.—This Act shall remain in effect until the date that is 5 years
    after the date of enactment, unless extended by Congress.

(b) STUDY.—Not later than 4 years after the date of enactment, the Government
    Accountability Office shall submit to Congress a comprehensive report on—
    (1) the accuracy and reliability of facial recognition technology;
    (2) disparate impact on protected classes;
    (3) the impact on civil rights and civil liberties;
    (4) recommendations for any future regulatory framework; and
    (5) whether the moratorium should be extended or made permanent.

SEC. 9. SEVERABILITY.

If any provision of this Act, or the application of such provision to any
person or circumstance, is held to be unconstitutional, the remainder of
this Act, and the application of the remaining provisions to any person or
circumstance, shall not be affected.

SEC. 10. EFFECTIVE DATE.

This Act shall take effect 90 days after the date of enactment.
```

---

### Fourth Amendment Is Not For Sale Act

```
SEC. 1. SHORT TITLE.

This Act may be cited as the "Fourth Amendment Is Not For Sale Act."

SEC. 2. FINDINGS.

Congress finds the following:

(1) The Fourth Amendment to the Constitution protects the right of individuals
    to be secure in their persons, houses, papers, and effects against
    unreasonable searches and seizures.

(2) Government agencies have increasingly circumvented Fourth Amendment
    protections by purchasing information from private data brokers that would
    otherwise require a warrant to obtain.

(3) Data brokers collect and aggregate vast quantities of personal information,
    including location data, communications metadata, and other sensitive
    information, often without the knowledge or meaningful consent of individuals.

(4) The purchase of such data by government agencies constitutes an end-run
    around constitutional protections and statutory limitations on government
    surveillance.

(5) Congress must act to close this loophole and ensure that Fourth Amendment
    protections cannot be evaded through commercial transactions.

SEC. 3. DEFINITIONS.

In this Act:

(1) COVERED CUSTOMER INFORMATION.—The term "covered customer information"
    means—
    (A) location information;
    (B) the content of communications;
    (C) metadata relating to communications;
    (D) web browsing history or search history;
    (E) identifying information linked to any information described in
        subparagraphs (A) through (D);
    (F) biometric information; and
    (G) any other information for which a warrant would be required for
        government collection under the Fourth Amendment.

(2) COVERED GOVERNMENT ENTITY.—The term "covered government entity" means any
    department, agency, bureau, or other entity of the executive branch of
    the Federal Government, including any independent agency.

(3) DATA BROKER.—The term "data broker" means an entity that, for valuable
    consideration, sells, licenses, or otherwise provides covered customer
    information that was collected by another entity to a covered government
    entity.

(4) THIRD PARTY.—The term "third party" means any person or entity other than
    the individual whose information is collected.

SEC. 4. PROHIBITION ON WARRANTLESS PURCHASE OF PERSONAL INFORMATION.

(a) GENERAL PROHIBITION.—Except as provided in subsection (b), it shall be
    unlawful for any covered government entity to—
    (1) purchase or otherwise obtain covered customer information from a data
        broker or other third party; or
    (2) use covered customer information purchased or obtained by another
        covered government entity from a data broker.

(b) EXCEPTION FOR WARRANTED COLLECTION.—A covered government entity may
    purchase or obtain covered customer information if—
    (1) the entity first obtains a warrant issued by a court of competent
        jurisdiction based on probable cause; or
    (2) an exception to the warrant requirement under the Fourth Amendment
        applies and would permit the government to compel the production of
        such information.

(c) CONTRACTS.—No covered government entity may enter into any contract,
    memorandum of understanding, or other agreement with a data broker or
    third party that would result in the receipt of covered customer
    information without a warrant.

SEC. 5. EVIDENTIARY PROHIBITION.

(a) EXCLUSIONARY RULE.—No information obtained in violation of section 4 may
    be received in evidence in any trial, hearing, or other proceeding before
    any court, grand jury, department, officer, agency, regulatory body,
    legislative committee, or other authority of the United States, a State,
    or a political subdivision thereof.

(b) DERIVATIVE EVIDENCE.—No evidence derived from information obtained in
    violation of section 4 may be received in evidence in any proceeding
    described in subsection (a).

SEC. 6. ENFORCEMENT.

(a) INSPECTOR GENERAL REVIEW.—The Inspector General of each covered government
    entity shall—
    (1) conduct annual audits of purchases of data from data brokers;
    (2) report findings to Congress; and
    (3) refer violations to the appropriate authorities for enforcement.

(b) PRIVATE RIGHT OF ACTION.—Any individual whose information is obtained in
    violation of this Act may bring a civil action against the responsible
    government entity and obtain—
    (1) actual damages;
    (2) statutory damages of not less than $10,000 per violation;
    (3) punitive damages;
    (4) attorney's fees and costs; and
    (5) injunctive relief.

SEC. 7. EFFECTIVE DATE.

This Act shall take effect 180 days after the date of enactment.
```

---

### Algorithmic Accountability in Criminal Justice Act

```
SEC. 1. SHORT TITLE.

This Act may be cited as the "Algorithmic Accountability in Criminal Justice
Act."

SEC. 2. FINDINGS.

Congress finds the following:

(1) Law enforcement agencies increasingly rely on algorithmic systems for
    critical decisions, including resource deployment, risk assessment, and
    identification of individuals.

(2) These systems are often developed by private vendors without public
    oversight, tested on unrepresentative data, and deployed without adequate
    evaluation of accuracy or bias.

(3) Studies have documented significant racial and socioeconomic disparities
    in the predictions and outcomes of algorithmic criminal justice systems.

(4) Due process requires that individuals have the ability to understand and
    challenge the basis for government actions that affect their liberty.

(5) Transparency, independent testing, and meaningful oversight are essential
    to ensuring that algorithmic systems are accurate, unbiased, and consistent
    with constitutional rights.

SEC. 3. DEFINITIONS.

In this Act:

(1) ALGORITHMIC SYSTEM.—The term "algorithmic system" means any computational
    process, including machine learning or artificial intelligence, that makes,
    assists in, or provides information to inform a decision by a law
    enforcement agency or criminal justice agency.

(2) COVERED DECISION.—The term "covered decision" means any decision that
    affects—
    (A) whether to investigate, detain, arrest, or prosecute an individual;
    (B) bail, pretrial detention, or release conditions;
    (C) sentencing recommendations;
    (D) parole or probation decisions;
    (E) allocation of law enforcement resources; or
    (F) any other decision that materially affects an individual's liberty
        or government investigation of an individual.

(3) IMPACT ASSESSMENT.—The term "impact assessment" means a systematic
    evaluation of an algorithmic system including its accuracy, reliability,
    disparate impact, and effects on civil rights and civil liberties.

SEC. 4. REQUIREMENTS FOR ALGORITHMIC SYSTEMS.

(a) IMPACT ASSESSMENT.—Before deploying any algorithmic system for covered
    decisions, and annually thereafter, a law enforcement agency shall—
    (1) conduct or commission an independent impact assessment;
    (2) make the impact assessment available to the public; and
    (3) provide a 60-day public comment period before deployment.

(b) CONTENT OF ASSESSMENT.—Each impact assessment shall include—
    (1) a description of the algorithmic system and its purpose;
    (2) the data used to develop and train the system;
    (3) accuracy metrics, including false positive and false negative rates;
    (4) analysis of disparate impact by race, ethnicity, gender, age, and
        socioeconomic status;
    (5) analysis of the system's impact on civil rights and civil liberties;
    (6) description of human oversight and discretion in the process; and
    (7) recommendations for mitigation of identified risks.

(c) INDEPENDENT EVALUATION.—Impact assessments shall be conducted by entities
    that are—
    (1) independent of the vendor and the deploying agency;
    (2) qualified to conduct technical evaluations; and
    (3) free from conflicts of interest.

SEC. 5. TRANSPARENCY REQUIREMENTS.

(a) PUBLIC DISCLOSURE.—Any law enforcement agency using an algorithmic system
    for covered decisions shall make publicly available—
    (1) a description of each system in use;
    (2) the purpose and scope of the system;
    (3) the vendor or developer;
    (4) the data sources used;
    (5) accuracy and error rates from impact assessments; and
    (6) any identified disparate impacts.

(b) DEFENDANT ACCESS.—Any defendant in a criminal case in which an algorithmic
    system was used shall have access to—
    (1) notice that an algorithmic system was used;
    (2) the information disclosed under subsection (a);
    (3) the specific inputs used for the defendant's case;
    (4) the output or recommendation produced; and
    (5) sufficient information to meaningfully challenge the system's reliability.

(c) PROHIBITION ON TRADE SECRET CLAIMS.—No claim of trade secret, proprietary
    information, or confidentiality shall limit the disclosures required by
    this section.

SEC. 6. PROHIBITION ON USE OF CERTAIN SYSTEMS.

(a) PROHIBITED SYSTEMS.—No Federal funds may be used to acquire, operate, or
    access an algorithmic system that—
    (1) has not undergone a required impact assessment;
    (2) demonstrates a disparate impact on protected classes that cannot be
        justified by a compelling governmental interest and achieved through
        the least restrictive means;
    (3) uses constitutionally protected activity, including First Amendment
        activities, as inputs; or
    (4) does not permit meaningful human oversight.

(b) PREDICTIVE POLICING RESTRICTION.—No algorithmic system may be used to
    predict that a specific individual will commit a crime or to generate
    a list of individuals for enhanced law enforcement scrutiny.

SEC. 7. EVIDENTIARY STANDARDS.

(a) ADMISSIBILITY.—No output, prediction, or recommendation from an algorithmic
    system may be admitted as evidence in any criminal proceeding unless—
    (1) the system has undergone an impact assessment meeting the requirements
        of this Act;
    (2) the defendant has been provided access to information required by
        section 5(b); and
    (3) the court finds that the system meets applicable scientific reliability
        standards.

(b) CORROBORATION.—No arrest, prosecution, or conviction may be based solely
    on the output of an algorithmic system.

SEC. 8. OVERSIGHT AND ENFORCEMENT.

(a) ATTORNEY GENERAL REVIEW.—The Attorney General shall—
    (1) establish minimum standards for algorithmic systems used in criminal
        justice;
    (2) review impact assessments and make determinations regarding compliance;
    (3) maintain a public database of approved systems; and
    (4) enforce the requirements of this Act.

(b) GRANT CONDITIONS.—As a condition of receiving any grant under any program
    administered by the Department of Justice, a recipient shall certify
    compliance with this Act.

(c) PRIVATE RIGHT OF ACTION.—Any individual adversely affected by a violation
    of this Act may bring a civil action and recover actual damages, statutory
    damages of not less than $10,000, attorney's fees, and injunctive relief.

SEC. 9. EFFECTIVE DATE.

This Act shall take effect one year after the date of enactment.
```

---

## State Model Legislation

### Model State Surveillance Oversight Act

```
SECTION 1. SHORT TITLE.

This Act may be cited as the "[State] Surveillance Oversight Act."

SECTION 2. DEFINITIONS.

As used in this Act:

(a) "Law enforcement agency" means any State, county, municipal, or other
    governmental agency that employs officers authorized to enforce criminal
    laws.

(b) "Surveillance technology" means any electronic device, system, or software
    designed, intended, or primarily used to collect, retain, process, or
    share audio, video, location, thermal, biometric, or similar information
    about individuals or groups, including but not limited to:
    (1) Facial recognition technology;
    (2) Automated license plate readers;
    (3) Cell site simulators;
    (4) Drones or unmanned aircraft equipped with surveillance capabilities;
    (5) Gunshot detection systems;
    (6) Predictive policing or algorithmic systems;
    (7) Social media monitoring tools;
    (8) Body-worn cameras with facial recognition or other biometric
        capabilities;
    (9) Video analytics or artificial intelligence systems; and
    (10) Any other technology designated by the [oversight body].

(c) "Surveillance impact report" means a publicly released written report
    that includes:
    (1) A description of the surveillance technology and its purpose;
    (2) The information that can be collected, processed, or shared;
    (3) The individuals, communities, or locations that may be surveilled;
    (4) The proposed retention period for collected information;
    (5) The entities with which information may be shared;
    (6) An analysis of potential disparate impacts on protected classes;
    (7) The civil rights and civil liberties implications;
    (8) The fiscal costs; and
    (9) The means by which the technology will be overseen.

(d) "Use policy" means a publicly released policy governing the use of
    surveillance technology that includes:
    (1) The purpose and scope of authorized use;
    (2) The data collection, retention, and sharing procedures;
    (3) The individuals authorized to access data;
    (4) Training requirements for personnel;
    (5) Audit procedures;
    (6) Complaint and redress procedures; and
    (7) Consequences for policy violations.

SECTION 3. LEGISLATIVE APPROVAL REQUIRED.

(a) No law enforcement agency shall acquire, borrow, obtain, or use any
    surveillance technology unless:
    (1) The agency has submitted a surveillance impact report and proposed
        use policy to the [Legislature/City Council/County Board];
    (2) A public hearing has been held;
    (3) The governing body has approved the acquisition or use by ordinance
        or resolution; and
    (4) A use policy has been adopted.

(b) This section applies to:
    (1) New acquisitions of surveillance technology;
    (2) Upgrades or modifications that expand capabilities;
    (3) Sharing or receiving surveillance technology from other agencies;
    (4) Contracting with third parties for surveillance services; and
    (5) Surveillance technology acquired prior to the effective date of
        this Act.

SECTION 4. ANNUAL REPORTING.

(a) Each law enforcement agency using surveillance technology shall submit
    an annual report to the governing body that includes:
    (1) A summary of how the technology was used;
    (2) The number of individuals or locations surveilled;
    (3) The demographic composition of individuals surveilled, if known;
    (4) The number of times collected information was shared and with whom;
    (5) The total costs of the technology;
    (6) Any complaints or concerns raised;
    (7) Any data breaches or security incidents;
    (8) An assessment of whether the technology achieved its stated purpose;
        and
    (9) Recommendations regarding continued use.

(b) Annual reports shall be made publicly available on the agency's website.

SECTION 5. SUNSET PROVISIONS.

(a) Any approval of surveillance technology under this Act shall expire
    after [two/three] years unless renewed by the governing body.

(b) Renewal shall require:
    (1) An updated surveillance impact report;
    (2) An updated use policy;
    (3) A public hearing; and
    (4) Affirmative approval by the governing body.

SECTION 6. DATA GOVERNANCE.

(a) Retention limits:
    (1) Unless otherwise specified in the use policy, surveillance data shall
        be deleted within [30/60/90] days of collection.
    (2) Data relevant to an active criminal investigation may be retained for
        the duration of the investigation.
    (3) Data subject to a litigation hold may be retained as required by law.

(b) Sharing restrictions:
    (1) Surveillance data shall not be shared with federal immigration
        enforcement agencies except pursuant to a judicial warrant.
    (2) Surveillance data shall not be sold or transferred to private entities.
    (3) All sharing shall be documented and reported annually.

(c) Access rights:
    (1) Upon request, any individual may learn whether they are the subject
        of surveillance data held by a law enforcement agency.
    (2) Individuals may request correction of inaccurate information.
    (3) Access may be delayed if it would compromise an active criminal
        investigation.

SECTION 7. PROHIBITED TECHNOLOGIES.

The following surveillance technologies are prohibited from use by any law
enforcement agency in this State:

(a) Facial recognition technology;

(b) Predictive policing algorithms that identify specific individuals as
    likely to commit crimes;

(c) Social media monitoring that tracks individuals based on political
    affiliation, religious belief, or exercise of First Amendment rights;

(d) [Additional prohibited technologies as determined by the Legislature].

SECTION 8. ENFORCEMENT.

(a) Any surveillance technology acquired or used in violation of this Act
    shall be deemed unlawfully obtained and may not be used.

(b) No information obtained through surveillance technology used in violation
    of this Act may be admitted as evidence in any criminal, civil, or
    administrative proceeding.

(c) Any individual subjected to surveillance in violation of this Act may
    bring a civil action and recover:
    (1) Actual damages;
    (2) Statutory damages of not less than $5,000 per violation;
    (3) Reasonable attorney's fees and costs; and
    (4) Injunctive relief.

(d) Any public employee who knowingly violates this Act shall be subject to
    discipline, up to and including termination.

SECTION 9. LOCAL AUTHORITY.

Nothing in this Act shall preempt a local jurisdiction from adopting more
restrictive limitations on surveillance technology.

SECTION 10. EFFECTIVE DATE.

This Act shall take effect on [date].
```

---

### Model State Facial Recognition Moratorium Act

```
SECTION 1. SHORT TITLE.

This Act may be cited as the "[State] Facial Recognition Moratorium Act."

SECTION 2. FINDINGS.

The Legislature finds:

(a) Facial recognition technology has demonstrated significant accuracy
    disparities, with error rates up to 35 times higher for Black women
    compared to white men.

(b) Facial recognition technology has led to documented wrongful arrests
    of innocent individuals.

(c) Facial recognition enables persistent surveillance incompatible with
    constitutional privacy protections.

(d) A moratorium is necessary to prevent ongoing harm while appropriate
    safeguards are developed.

SECTION 3. DEFINITIONS.

(a) "Facial recognition technology" means any automated or semi-automated
    process that assists in identifying or verifying an individual based on
    the physical characteristics of an individual's face.

(b) "State agency" means any department, agency, or other governmental unit
    of the State.

(c) "Local agency" means any county, city, town, or other political
    subdivision of the State.

SECTION 4. MORATORIUM.

(a) No State agency shall:
    (1) Acquire, possess, access, or use facial recognition technology;
    (2) Contract with any entity to use facial recognition technology on
        behalf of the State; or
    (3) Use, request, or accept information derived from facial recognition
        technology from any source.

(b) No local agency shall engage in the activities described in subsection (a).

(c) This moratorium shall remain in effect until:
    (1) The Legislature enacts comprehensive regulations governing facial
        recognition technology based on the study required by Section 5; and
    (2) Independent testing demonstrates that facial recognition systems
        meet accuracy and equity standards established by such regulations.

SECTION 5. STUDY COMMISSION.

(a) There is hereby established a Facial Recognition Technology Study
    Commission.

(b) The Commission shall study and make recommendations regarding:
    (1) The accuracy and reliability of facial recognition technology;
    (2) Disparate impact on protected classes;
    (3) Appropriate use cases, if any;
    (4) Required accuracy standards;
    (5) Transparency and oversight requirements;
    (6) Due process protections;
    (7) Data retention and sharing limitations; and
    (8) Enforcement mechanisms.

(c) The Commission shall submit a report to the Legislature within [two years]
    of the effective date of this Act.

SECTION 6. ENFORCEMENT.

(a) No information obtained through facial recognition technology in
    violation of this Act may be admitted as evidence.

(b) Any individual subjected to facial recognition in violation of this Act
    may bring a civil action and recover actual damages, statutory damages
    of $10,000, and attorney's fees.

SECTION 7. EFFECTIVE DATE.

This Act shall take effect immediately upon enactment.
```

---

### Model State License Plate Reader Privacy Act

```
SECTION 1. SHORT TITLE.

This Act may be cited as the "[State] License Plate Reader Privacy Act."

SECTION 2. DEFINITIONS.

(a) "Automated license plate reader" or "ALPR" means any device or system
    that uses cameras and computer algorithms to automatically capture,
    record, or analyze license plate images.

(b) "ALPR data" means any image, information, or record captured by an ALPR,
    including license plate numbers, vehicle characteristics, and location
    and time information.

(c) "Hit" means a match between an ALPR scan and a plate on a designated
    alert list.

(d) "Non-hit data" means ALPR data that does not result in a hit.

SECTION 3. DATA RETENTION LIMITS.

(a) Non-hit data shall be deleted within [48 hours/7 days/30 days] of
    collection.

(b) Hit data may be retained for the duration of any related investigation,
    but not longer than [one year] absent an ongoing investigation or
    prosecution.

(c) No ALPR data shall be retained indefinitely.

SECTION 4. USE RESTRICTIONS.

(a) ALPR systems may only be used for:
    (1) Identifying stolen vehicles;
    (2) Locating vehicles associated with missing persons;
    (3) Locating vehicles subject to outstanding warrants; and
    (4) [Other specified purposes].

(b) ALPR systems shall not be used to:
    (1) Track individuals exercising First Amendment rights;
    (2) Enforce immigration laws;
    (3) Monitor individuals based on protected characteristics;
    (4) Track the location of individuals without reasonable suspicion of
        criminal activity; or
    (5) Any purpose not authorized by subsection (a).

SECTION 5. WARRANT REQUIREMENT.

(a) No law enforcement agency may query historical ALPR data for periods
    exceeding [24/48] hours without a warrant based on probable cause.

(b) Real-time alerts for hits on designated lists do not require a warrant
    but must be supported by a legitimate law enforcement purpose documented
    prior to the query.

SECTION 6. SHARING RESTRICTIONS.

(a) ALPR data shall not be shared with federal immigration enforcement
    agencies except pursuant to a judicial warrant.

(b) ALPR data shall not be sold, transferred, or shared with commercial
    entities.

(c) All data sharing with other law enforcement agencies shall be documented
    and reported annually.

SECTION 7. TRANSPARENCY AND REPORTING.

(a) Each agency operating ALPRs shall publish annually:
    (1) The number and locations of ALPR devices;
    (2) The total number of plates scanned;
    (3) The number of hits generated;
    (4) The number of investigations initiated based on ALPR data;
    (5) The demographic composition of areas surveilled;
    (6) Data sharing agreements and recipients; and
    (7) The costs of the ALPR program.

SECTION 8. ENFORCEMENT.

(a) ALPR data collected or used in violation of this Act shall be
    inadmissible as evidence.

(b) Individuals may bring civil actions for violations, with statutory
    damages of $2,500 per violation, plus attorney's fees.

SECTION 9. EFFECTIVE DATE.

This Act shall take effect [180 days] after enactment.
```

---

## Local Model Ordinances

### Model Community Control Over Police Surveillance (CCOPS) Ordinance

```
SECTION 1. TITLE.

This ordinance may be cited as the "[City] Surveillance Technology Ordinance."

SECTION 2. PURPOSE.

The purpose of this ordinance is to ensure comprehensive community oversight
of surveillance technology, protect civil rights and civil liberties, and
provide for transparency and accountability in the acquisition and use of
surveillance technology by City agencies.

SECTION 3. DEFINITIONS.

[Definitions substantially similar to state model above]

SECTION 4. CITY COUNCIL APPROVAL REQUIRED.

(a) No City agency shall acquire, borrow, obtain, or use any surveillance
    technology without prior City Council approval.

(b) Prior to City Council consideration, the agency shall:
    (1) Submit a surveillance impact report to the City Council;
    (2) Submit a proposed use policy;
    (3) Publish the materials on the City's website for at least 30 days; and
    (4) Present the proposal at a public hearing.

(c) The City Council shall approve or reject the proposal by ordinance.

SECTION 5. SURVEILLANCE IMPACT REPORT.

Each surveillance impact report shall include:

(a) A description of the technology and its purpose;
(b) The information to be collected;
(c) Proposed retention periods;
(d) Proposed data sharing;
(e) Analysis of potential civil rights and civil liberties impacts;
(f) Analysis of potential disparate impacts on protected classes;
(g) Safeguards to protect privacy;
(h) Fiscal analysis; and
(i) Alternatives considered.

SECTION 6. USE POLICY REQUIREMENTS.

Each use policy shall include:

(a) Purpose and scope of authorized uses;
(b) Data collection procedures;
(c) Data retention limits;
(d) Data sharing restrictions;
(e) Access limitations;
(f) Training requirements;
(g) Audit procedures;
(h) Oversight mechanisms;
(i) Complaint procedures; and
(j) Consequences for policy violations.

SECTION 7. ANNUAL REPORTING.

[Provisions substantially similar to state model above]

SECTION 8. SUNSET AND RENEWAL.

All approvals expire after [two years] and require renewal through the
same process as initial approval.

SECTION 9. ENFORCEMENT.

(a) Any surveillance technology acquired or used in violation of this
    ordinance may not be used, and information obtained may not be admitted
    as evidence.

(b) Any individual subjected to surveillance in violation of this ordinance
    may bring a civil action for actual damages, statutory damages of $1,000
    per violation, and attorney's fees.

SECTION 10. EFFECTIVE DATE.

This ordinance shall take effect [30 days] after enactment.
```

---

## Loopholes, Shortcomings, and Rectification

This section identifies common weaknesses in surveillance technology legislation and provides recommendations for addressing them.

### Federal Legislation Loopholes

| Loophole | Description | Rectification |
|----------|-------------|---------------|
| National security exception | Allows surveillance under national security justifications | Require FISA court approval; sunset provisions; congressional notification |
| Third-party purchases | Government buys data from brokers to avoid warrant requirements | Prohibit purchase of data that would require a warrant to obtain directly |
| Foreign intelligence exception | Allows warrantless surveillance of communications with non-US persons | Require warrant for any surveillance of US persons |
| Standing barriers | Victims cannot prove surveillance to establish standing | Create statutory standing for anyone in surveilled area |
| Qualified immunity | Officers rarely held personally liable | Eliminate qualified immunity for surveillance violations |
| Classification | Capabilities classified, preventing public accountability | Require unclassified summaries; congressional oversight |
| Emergency exceptions | Broad emergency exceptions swallow the rule | Narrow emergencies; require after-the-fact judicial review |
| Consent loopholes | Third-party consent vitiates protections | Require target's consent or warrant |

### State Legislation Loopholes

| Loophole | Description | Rectification |
|----------|-------------|---------------|
| Preemption clauses | State laws preempt stronger local protections | Expressly preserve local authority to enact stronger protections |
| Exemption for existing technology | Grandfathers in current surveillance | Require retroactive compliance within defined timeframe |
| Weak enforcement | No private right of action; inadequate penalties | Strong private right of action; meaningful damages; attorney fee shifting |
| Undefined terms | Vague definitions of surveillance technology | Comprehensive definitions that anticipate new technologies |
| Information sharing loopholes | No restrictions on receiving data from other sources | Prohibit use of data obtained in violation of state law regardless of source |
| Consent screens | Notice and consent deemed sufficient | Recognize power imbalances; require meaningful consent standards |
| Contractor exception | Requirements apply to agencies but not contractors | Extend requirements to all contractors and subcontractors |
| Cross-jurisdictional sharing | No limits on sharing with federal agencies | Prohibit sharing with federal agencies for immigration enforcement |

### Local Ordinance Loopholes

| Loophole | Description | Rectification |
|----------|-------------|---------------|
| Advisory only oversight | Oversight bodies lack enforcement power | Grant binding authority; subpoena power; disciplinary recommendations |
| Emergency acquisitions | Allow rapid acquisition without oversight | Narrow emergency definition; require retrospective approval |
| Pilot program exceptions | Allow extended pilots without full approval | Time-limited pilots with mandatory full review |
| Gift acceptance loopholes | Accept donated equipment without oversight | Require approval for gifts and donations |
| Interoperability gaps | Systems shared between jurisdictions | Require approval for any interoperability or data sharing |
| Weak reporting requirements | Minimal or optional reporting | Mandatory comprehensive annual reports with public hearings |
| No sunset provisions | Approvals last indefinitely | Require periodic reauthorization (2-3 year maximum) |
| Inadequate notice | No notice to affected individuals | Require notice when feasible; general public notice of surveillance |

### Cross-Cutting Shortcomings

| Shortcoming | Description | Rectification |
|-------------|-------------|---------------|
| Algorithm opacity | Proprietary claims shield scrutiny | Prohibit trade secret claims for systems affecting liberty |
| Vendor non-disclosure | NDAs prevent public transparency | Void NDAs that conflict with disclosure requirements |
| Accuracy claims unverified | Vendors self-report accuracy | Require independent third-party testing |
| Disparate impact ignored | No requirement to assess bias | Mandatory bias audits; prohibition if disparate impact shown |
| First Amendment blind spots | Surveillance of protected activity | Explicit protections for political and religious activity |
| Consent theater | Meaningless consent procedures | Robust consent standards; limits on consent-based collection |
| Facial recognition carve-outs | Exceptions for specific uses | Comprehensive bans without exceptions |
| Retroactive data use | Historical data not covered | Apply restrictions to all data regardless of collection date |
| Contractor loopholes | Private companies not covered | Equal requirements for private sector partnerships |
| Data broker loopholes | No restrictions on commercial surveillance | Extend public sector rules to data broker purchases |

### Enforcement Weaknesses

| Weakness | Description | Rectification |
|----------|-------------|---------------|
| No exclusionary rule | Illegally obtained evidence admissible | Mandatory exclusion of evidence from violations |
| Inadequate damages | Statutory damages too low to deter | Meaningful minimum damages ($10,000+); treble damages for willful violations |
| No fee shifting | Plaintiffs bear litigation costs | Mandatory attorney fee shifting for prevailing plaintiffs |
| Individual liability shields | Officers not personally liable | Eliminate qualified immunity; create personal liability |
| No administrative enforcement | No agency oversight | Create enforcement agency with investigation and penalty authority |
| Criminal penalty gaps | No criminal liability for violations | Criminal penalties for intentional violations |
| Statute of limitations | Too short for discovery of violations | Extended limitations; tolling during concealment |
| Class action barriers | Difficult to aggregate claims | Facilitate class actions; representative actions |

---

## Implementation Notes

When adapting this model legislation:

1. **Consult local counsel** to ensure compatibility with state constitution and existing law
2. **Engage stakeholders** including impacted communities, civil liberties groups, and law enforcement
3. **Build coalitions** across political spectrum where possible
4. **Anticipate opposition** and prepare responses to common arguments
5. **Plan for enforcement** including oversight bodies, funding, and accountability mechanisms
6. **Include sunset provisions** requiring periodic reauthorization
7. **Preserve local authority** to enact stronger protections
8. **Address all loopholes** identified in the tables above

---

## Document Navigation

| Previous | Current | Next |
|----------|---------|------|
| [10-actions.md](10-actions.md) | [11-legislation.md](11-legislation.md) | — |

**All Documents in This Series:**
- [01-overview.md](01-overview.md) - Executive Summary
- [02-current-state.md](02-current-state.md) - Current State of Surveillance Technology
- [03-history.md](03-history.md) - Historical Development
- [04-root-causes.md](04-root-causes.md) - Root Causes of Expansion
- [05-stakeholders.md](05-stakeholders.md) - Key Stakeholders
- [06-opposition.md](06-opposition.md) - Opposition to Reform
- [07-solutions.md](07-solutions.md) - Proposed Solutions
- [08-roadmap.md](08-roadmap.md) - Implementation Roadmap
- [09-resources.md](09-resources.md) - Resources and Further Reading
- [10-actions.md](10-actions.md) - Action Guide
- [11-legislation.md](11-legislation.md) - Model Legislation
